# ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ë° íƒìƒ‰í•˜ê¸°

ì´ ì½”ìŠ¤ì—ì„œ ìš°ë¦¬ëŠ” ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹ì„ ë‹¤ë£¹ë‹ˆë‹¤.ğŸ¤— DatasetsëŠ” ì˜¤ë””ì˜¤ë¥¼ í¬í•¨í•œ ëª¨ë“  ì–‘ì‹ì˜ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¤€ë¹„í•  ìˆ˜ ìˆëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” í—ˆê¹…í˜ì´ìŠ¤ í—ˆë¸Œì—ì„œ ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¨¸ì‹ ëŸ¬ë‹ ë°ì´í„°ì…‹ì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. ë¬´ì—‡ë³´ë‹¤ë„, ğŸ¤— DatasetsëŠ” ì—°êµ¬ìì™€ ì‹¤ë¬´ì ëª¨ë‘ê°€ ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹ì„ ì‰½ê²Œ ë‹¤ë£° ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” íŠ¹í™” ê¸°ëŠ¥ë“¤ì„ ì—¬ëŸ¿ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

ì‹œì‘ì— ì•ì„œ, ğŸ¤— Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë¼ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:

```bash
pip install datasets[audio]
```

ğŸ¤— Datasetsì˜ ì£¼ëœ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” `load_dataset()` íŒŒì´ì¬ ì½”ë“œ í•œì¤„ë¡œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¤€ë¹„í•  ìˆ˜ ìˆë‹¤ëŠ”ê²ƒì…ë‹ˆë‹¤.


[MINDS-14](https://huggingface.co/datasets/PolyAI/minds14)ë¼ê³  í•˜ëŠ” ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ ë‹¤ë¤„ë´…ì‹œë‹¤. ì´ ë°ì´í„°ì…‹ì€ ì—¬ëŸ¬ ì–¸ì–´ì™€ ë°©ì–¸ìœ¼ë¡œ ì‚¬ëŒë“¤ì´ ì¸í„°ë„·ë±…í‚¹ì— ëŒ€í•´ ë¬»ëŠ” ë‚´ìš©ì´ ë…¹ìŒë¼ìˆìŠµë‹ˆë‹¤.

MINDS-14 ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ í—ˆë¸Œì—ì„œì˜ ë°ì´í„°ì…‹ ì‹ë³„ìì¸ (`PolyAI/minds14`)ë¥¼ `load_dataset` í•¨ìˆ˜ë¡œ ë„˜ê²¨ì¤˜ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ë°ì´í„°ì…‹ì˜ í˜¸ì£¼ ë¶€ë¶„(`en-AU`)ì—ë§Œ ê´€ì‹¬ì´ ìˆê³  í•™ìŠµìš© ë°ì´í„°ì—ë§Œ ê´€ì‹¬ì´ ìˆìŒì„ ëª…ì‹œí•˜ê² ìŠµë‹ˆë‹¤.:

```py
from datasets import load_dataset

minds = load_dataset("PolyAI/minds14", name="en-AU", split="train")
minds
```

**Output:**
```out
Dataset(
    {
        features: [
            "path",
            "audio",
            "transcription",
            "english_transcription",
            "intent_class",
            "lang_id",
        ],
        num_rows: 654,
    }
)
```

ë°ì´í„°ì…‹ì€ 654ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ì´ë¤„ì ¸ìˆìŠµë‹ˆë‹¤. ê°ê°ì˜ íŒŒì¼ë“¤ì€ ìë§‰, ì˜ì–´ ë²ˆì—­, ê·¸ë¦¬ê³  ì§ˆë¬¸ìì˜ ì˜ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë ˆì´ë¸”(label)ì´ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ì»¬ëŸ¼(column)ì—ëŠ” ì›ì‹œ(raw) ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì˜ˆì œë¥¼ í•˜ë‚˜ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:

```py
example = minds[0]
example
```

**Output:**
```out
{
    "path": "/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-AU~PAY_BILL/response_4.wav",
    "audio": {
        "path": "/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-AU~PAY_BILL/response_4.wav",
        "array": array(
            [0.0, 0.00024414, -0.00024414, ..., -0.00024414, 0.00024414, 0.0012207],
            dtype=float32,
        ),
        "sampling_rate": 8000,
    },
    "transcription": "I would like to pay my electricity bill using my card can you please assist",
    "english_transcription": "I would like to pay my electricity bill using my card can you please assist",
    "intent_class": 13,
    "lang_id": 2,
}
```

ì˜¤ë””ì˜¤ ì»¬ëŸ¼ì— ì—¬ëŸ¬ featureê°€ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°ê°ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: 
* `path`: ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê²½ë¡œ(ì´ ì˜ˆì œì˜ ê²½ìš° `*.wav`).
* `array`: 1ì°¨ì› ë„˜íŒŒì´ ë°°ì—´ë¡œ ë””ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„°.
* `sampling_rate`: ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ìƒ˜í”Œë§ ì†ë„(ì´ ì˜ˆì œì˜ ê²½ìš° 8,000 Hz).


`intent_class`ëŠ” ì˜¤ë””ì˜¤ ë…¹ìŒì´ ì–´ë–¤ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜ë˜ëŠ”ì§€ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ìˆ«ìë¥¼ ì˜ë¯¸ìˆëŠ” ë¬¸ìì—´ë¡œ ë°”ê¾¸ë ¤ë©´ `int2str()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:

```py
id2label = minds.features["intent_class"].int2str
id2label(example["intent_class"])
```

**Output:**
```out
"pay_bill"
```

`transcription` featureë¥¼ ë³´ë©´ ëˆ„êµ°ê°€ê°€ ì²­êµ¬ì„œë¥¼ ì§€ë¶ˆí•˜ëŠ” ê²ƒì— ëŒ€í•´ ì§ˆë¬¸í•˜ëŠ” ë…¹ìŒì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì´ë€ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ë°ì´í„°ì˜ ë¶€ë¶„ì§‘í•©ì— ëŒ€í•´ ì˜¤ë””ì˜¤ ë¶„ë¥˜ê¸°(classifier)ë¥¼ í•™ìŠµì‹œí‚¬ ê³„íšì´ì‹œë¼ë©´, ì´ ëª¨ë“  featureê°€ í•„ìš”í•˜ì§„ ì•Šì„ì§€ë„ ëª¨ë¦…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `lang_id`ëŠ” ëª¨ë“  ì˜ˆì œì—ì„œ ê°™ì€ ê°’ì„ ì§€ë‹ˆê¸° ë•Œë¬¸ì— ê·¸ë‹¤ì§€ ì“¸ëª¨ ìˆì§€ ì•Šì„ê²ë‹ˆë‹¤.  `english_transcription`ëŠ” ì´ í˜¸ì£¼ë°ì´í„°ì—ì„  ëŒ€ë¶€ë¶„ì´ `transcription`ê³¼ ê°™ì„í…Œë‹ˆ ì‚­ì œí•´ë„ ì¢‹ì„ê²ë‹ˆë‹¤.

ì´ëŸ° ê´€ê³„ì—†ëŠ” featureëŠ” ğŸ¤— Datasetsì˜ `remove_columns` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
columns_to_remove = ["lang_id", "english_transcription"]
minds = minds.remove_columns(columns_to_remove)
minds
```

**Output:**
```out
Dataset({features: ["path", "audio", "transcription", "intent_class"], num_rows: 654})
```

ì´ì œ ë°ì´í„°ì…‹ì˜ ì›ì‹œ ì»¨í…ì¸ ë“¤ì„ ë¶ˆëŸ¬ì˜¤ê³  ì‚´í´ë´¤ìœ¼ë‹ˆ, ëª‡ê°œë¥¼ ë“¤ì–´ë´…ì‹œë‹¤!
`Gradio`ì˜ `Blocks`ì™€ `Audio` ê¸°ëŠ¥ì„ ì¨ì„œ ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ëª‡ê°œë¥¼ ë¬´ì‘ìœ„ë¡œ ë””ì½”ë”©í•´ë³´ê² ìŠµë‹ˆë‹¤:

```py
import gradio as gr


def generate_audio():
    example = minds.shuffle()[0]
    audio = example["audio"]
    return (
        audio["sampling_rate"],
        audio["array"],
    ), id2label(example["intent_class"])


with gr.Blocks() as demo:
    with gr.Column():
        for _ in range(4):
            audio, label = generate_audio()
            output = gr.Audio(audio, label=label)

demo.launch(debug=True)
```

ì›í•˜ì‹ ë‹¤ë©´, ì˜ˆì œ ëª‡ê°œë¥¼ ì‹œê°í™”í•´ë³´ëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤. ì²«ë²ˆì§¸ ì˜ˆì œì˜ íŒŒí˜•ì„ ê·¸ë ¤ë³´ê² ìŠµë‹ˆë‹¤.

```py
import librosa
import matplotlib.pyplot as plt
import librosa.display

array = example["audio"]["array"]
sampling_rate = example["audio"]["sampling_rate"]

plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/waveform_unit1.png" alt="Waveform plot">
</div>

í•œë²ˆ í•´ë³´ì„¸ìš”! MINDS-14 ë°ì´í„°ì…‹ì˜ ë‹¤ë¥¸ ì–¸ì–´ë‚˜ ë°©ì–¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë“£ê³  ì‹œê°í™”ë¥¼ í•´ë³´ì„¸ìš”. ì „ì²´ ë°ì´í„°ì…‹ì´ ì–´ë–¨ì§€ ëŒ€ëµì ì¸ ê°ì„ ì¤„ê²ë‹ˆë‹¤. [ì—¬ê¸°](https://huggingface.co/datasets/PolyAI/minds14)ì„œ ê°€ëŠ¥í•œ ì–¸ì–´ë“¤ì´ ë¬´ì—‡ì¸ì§€ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
