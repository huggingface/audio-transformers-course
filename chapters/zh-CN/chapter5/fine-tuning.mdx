# å¾®è°ƒè¯­éŸ³è¯†åˆ«æ¨¡å‹

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ‰‹æŠŠæ‰‹æŒ‡å¯¼å¦‚ä½•åœ¨ Common Voice 13 æ•°æ®é›†ä¸Šå¾®è°ƒ Whisper ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«ã€‚
æˆ‘ä»¬å°†ä½¿ç”¨æ¨¡å‹çš„â€œsmallâ€ç‰ˆæœ¬å’Œä¸€ä¸ªç›¸å¯¹è½»é‡çº§çš„æ•°æ®é›†ï¼Œä½¿æ‚¨èƒ½å¤Ÿåœ¨ä»»ä½• 16GB ä»¥ä¸Šçš„ GPU ä¸Šç”¨å°‘é‡ç£ç›˜ç©ºé—´ç›¸å¯¹å¿«é€Ÿåœ°å¾®è°ƒï¼Œ
ä¾‹å¦‚ Google Colab å…è´¹æä¾›çš„ 16GB T4 GPUã€‚

å¦‚æœæ‚¨çš„ GPU å¤ªå°ï¼Œæˆ–åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°å†…å­˜é—®é¢˜ï¼Œå¯ä»¥éµå¾ªæˆ‘ä»¬ä¹‹åæä¾›çš„å»ºè®®æ¥å‡å°‘å†…å­˜ä½¿ç”¨é‡ã€‚
ç›¸åï¼Œå¦‚æœæ‚¨å¯ä»¥è®¿é—®æ›´å¤§çš„ GPUï¼Œæ‚¨å¯ä»¥ä¿®æ”¹è®­ç»ƒå‚æ•°ä»¥æœ€å¤§åŒ–æ‚¨çš„ååé‡ã€‚å› æ­¤ï¼Œæ— è®ºæ‚¨çš„ GPU è§„æ ¼å¦‚ä½•ï¼Œéƒ½å¯ä»¥å‚è€ƒæœ¬æŒ‡å—ï¼

åŒæ ·ï¼Œæœ¬æŒ‡å—ç®€è¦ä»‹ç»äº†å¦‚ä½•é’ˆå¯¹è¿ªç»´å¸Œè¯­å¾®è°ƒ Whisper æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™é‡Œä»‹ç»çš„æ­¥éª¤å¯ä»¥æ¨å¹¿åˆ° Common Voice æ•°æ®é›†ä¸­çš„ä»»ä½•è¯­è¨€ï¼Œ
æ›´ä¸€èˆ¬åœ°ï¼Œå¯ä»¥æ¨å¹¿åˆ° Hugging Face Hub ä¸Šçš„ä»»ä½• ASR æ•°æ®é›†ã€‚æ‚¨å¯ä»¥æ›´æ”¹ä»£ç ä»¥å¿«é€Ÿåˆ‡æ¢åˆ°æ‚¨é€‰æ‹©çš„è¯­è¨€ï¼Œå¹¶åœ¨æ‚¨çš„æ¯è¯­ä¸Šå¾®è°ƒ Whisper æ¨¡å‹ ğŸŒ

å¥½äº†ï¼ŒåºŸè¯å°‘è¯´ï¼Œè®©æˆ‘ä»¬å¼€å§‹æˆ‘ä»¬çš„å¾®è°ƒæµç¨‹å§ï¼

## é…ç½®ç¯å¢ƒ

æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨åœ¨è®­ç»ƒæ—¶ç›´æ¥å°†æ¨¡å‹æ£€æŸ¥ç‚¹ä¸Šä¼ è‡³ [Hugging Face Hub](https://huggingface.co/)ã€‚Hub æä¾›ï¼š

- é›†æˆçš„ç‰ˆæœ¬æ§åˆ¶ï¼šæ‚¨å¯ä»¥ç¡®ä¿è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ä¼šä¸¢å¤±ä»»ä½•æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚
- Tensorboard æ—¥å¿—ï¼šè·Ÿè¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦æŒ‡æ ‡ã€‚
- æ¨¡å‹å¡ç‰‡ï¼šè®°å½•æ¨¡å‹çš„åŠŸèƒ½åŠå…¶é¢„æœŸç”¨ä¾‹ã€‚
- ç¤¾åŒºï¼šä¸ç¤¾åŒºå…±äº«å’Œåä½œçš„ç®€ä¾¿æ–¹å¼ï¼ğŸ¤—

å°† notebook é“¾æ¥åˆ° Hub éå¸¸ç®€å•â€”â€”åªéœ€è¦è¾“å…¥æ‚¨çš„ Hub è®¤è¯ä»¤ç‰Œã€‚åœ¨ [è¿™é‡Œ](https://huggingface.co/settings/tokens) æ‰¾åˆ°æ‚¨çš„ Hub è®¤è¯ä»¤ç‰Œå¹¶æ ¹æ®æç¤ºè¾“å…¥å®ƒï¼š

```python
from huggingface_hub import notebook_login

notebook_login()
```

**è¾“å‡ºï¼š**

```bash
Login successful
Your token has been saved to /root/.huggingface/token
```

## åŠ è½½æ•°æ®é›†

[Common Voice 13](https://huggingface.co/datasets/mozilla-foundation/common_voice_13_0) åŒ…å«å¤§çº¦åå°æ—¶çš„æ ‡æ³¨è¿‡çš„è¿ªç»´å¸Œè¯­æ•°æ®ï¼Œ
è¿™å¯¹äºå¾®è°ƒæ¥è¯´æ˜¯æå°‘é‡çš„æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å°†ä¾èµ–åœ¨é¢„è®­ç»ƒæœŸé—´ Whisper è·å¾—çš„å¹¿æ³›çš„å¤šè¯­è¨€ ASR çŸ¥è¯†æ¥å¼¥è¡¥è¿ªç»´å¸Œè¯­çš„ä½èµ„æºé‡ã€‚

ä½¿ç”¨ ğŸ¤— Datasets ä¸‹è½½å’Œå‡†å¤‡æ•°æ®éå¸¸ç®€å•ã€‚æˆ‘ä»¬å¯ä»¥ç”¨ä¸€è¡Œä»£ç ä¸‹è½½å¹¶å‡†å¤‡å¥½ Common Voice 13 çš„æ•°æ®ã€‚ç”±äºè¿ªç»´å¸Œè¯­èµ„æºéå¸¸å°‘ï¼Œ
æˆ‘ä»¬å°†ç»“åˆ `train` å’Œ `validation` å­é›†ï¼Œæä¾›å¤§çº¦ä¸ƒå°æ—¶çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶ä½¿ç”¨ä¸‰å°æ—¶çš„ `test` æ•°æ®ä½œä¸ºæˆ‘ä»¬ä¿ç•™çš„æµ‹è¯•é›†ï¼š

```python
from datasets import load_dataset, DatasetDict

common_voice = DatasetDict()

common_voice["train"] = load_dataset(
    "mozilla-foundation/common_voice_13_0", "dv", split="train+validation"
)
common_voice["test"] = load_dataset(
    "mozilla-foundation/common_voice_13_0", "dv", split="test"
)

print(common_voice)
```

**è¾“å‡ºï¼š**

```
DatasetDict({
    train: Dataset({
        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],
        num_rows: 4904
    })
    test: Dataset({
        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],
        num_rows: 2212
    })
})
```

<Tip>
    æ‚¨å¯ä»¥å°†è¯­è¨€æ ‡è¯†ç¬¦ä» `"dv"` æ›´æ”¹ä¸ºæ‚¨é€‰æ‹©çš„è¯­è¨€æ ‡è¯†ç¬¦ã€‚è¦æŸ¥çœ‹ Common Voice 13 ä¸­æ‰€æœ‰å¯é€‰çš„è¯­è¨€ï¼Œ
    è¯·æŸ¥çœ‹ Hugging Face Hub ä¸Šçš„æ•°æ®é›†å¡ç‰‡ï¼šhttps://huggingface.co/datasets/mozilla-foundation/common_voice_13_0
</Tip>

å¤§å¤šæ•° ASR æ•°æ®é›†åªæä¾›è¾“å…¥éŸ³é¢‘æ ·æœ¬ï¼ˆ`audio`ï¼‰å’Œç›¸åº”çš„è½¬å†™æ–‡æœ¬ï¼ˆ`sentence`ï¼‰ã€‚Common Voice åŒ…å«é¢å¤–çš„å…ƒæ•°æ®ï¼Œå¦‚ `accent` å’Œ `locale`ï¼Œ
æˆ‘ä»¬åš ASR æ—¶å¯ä»¥å¿½ç•¥è¿™äº›ä¿¡æ¯ã€‚ä¸ºäº†è®©ä»£ç å°½å¯èƒ½é€šç”¨ï¼Œæˆ‘ä»¬åªç”¨è¾“å…¥éŸ³é¢‘å’Œè½¬å†™æ–‡æœ¬æ¥è¿›è¡Œå¾®è°ƒï¼Œä¸¢å¼ƒé¢å¤–çš„å…ƒæ•°æ®ä¿¡æ¯ï¼š

```python
common_voice = common_voice.select_columns(["audio", "sentence"])
```

## ç‰¹å¾æå–å™¨ã€åˆ†è¯å™¨å’Œå¤„ç†å™¨

ASR æµç¨‹å¯ä»¥åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š

1. ç‰¹å¾æå–å™¨å°†åŸå§‹éŸ³é¢‘è¾“å…¥é¢„å¤„ç†ä¸º log-mel é¢‘è°±å›¾
2. æ¨¡å‹æ‰§è¡Œåºåˆ—åˆ°åºåˆ—çš„æ˜ å°„
3. åˆ†è¯å™¨å°†é¢„æµ‹çš„è¯å…ƒåå¤„ç†ä¸ºæ–‡æœ¬

åœ¨ ğŸ¤— Transformers ä¸­ï¼ŒWhisper æ¨¡å‹æœ‰ä¸€ä¸ªå…³è”çš„ç‰¹å¾æå–å™¨å’Œåˆ†è¯å™¨ï¼Œåˆ†åˆ«ç§°ä¸º [WhisperFeatureExtractor](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperFeatureExtractor) å’Œ [WhisperTokenizer](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperTokenizer)ã€‚
ä¸ºäº†ç®€åŒ–æˆ‘ä»¬çš„å·¥ä½œï¼Œè¿™ä¸¤ä¸ªç±»çš„å¯¹è±¡åˆå¯ä»¥è¢«å°è£…åœ¨ä¸€ä¸ªç±»ä¸­ï¼Œç§°ä¸º [WhisperProcessor](https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperProcessor)ã€‚
æˆ‘ä»¬å¯ä»¥è°ƒç”¨ WhisperProcessor æ¥æ‰§è¡ŒéŸ³é¢‘é¢„å¤„ç†å’Œæ–‡æœ¬è¯å…ƒåå¤„ç†ã€‚è¿™æ ·æˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´åªéœ€è¦è·Ÿè¸ªä¸¤ä¸ªå¯¹è±¡ï¼šå¤„ç†å™¨å’Œæ¨¡å‹ã€‚

å½“æ‰§è¡Œå¤šè¯­è¨€å¾®è°ƒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å®ä¾‹åŒ–å¤„ç†å™¨æ—¶è®¾ç½® `"language"` å’Œ `"task"`ã€‚`"language"` åº”è®¾ç½®ä¸ºæºéŸ³é¢‘è¯­è¨€ï¼Œ
ä»»åŠ¡è®¾ç½®ä¸º `"transcribe"` ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«æˆ– `"translate"` ä»¥è¿›è¡Œè¯­éŸ³ç¿»è¯‘ã€‚è¿™äº›å‚æ•°ä¼šå½±å“åˆ†è¯å™¨çš„è¡Œä¸ºï¼Œåº”æ­£ç¡®è®¾ç½®ä»¥ç¡®ä¿ç›®æ ‡æ ‡ç­¾è¢«æ­£ç¡®ç¼–ç ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¼å…¥è¯­è¨€åˆ—è¡¨æ¥æŸ¥çœ‹ Whisper æ”¯æŒçš„æ‰€æœ‰å¯èƒ½è¯­è¨€ï¼š

```python
from transformers.models.whisper.tokenization_whisper import TO_LANGUAGE_CODE

TO_LANGUAGE_CODE
```

å¦‚æœæ‚¨æµè§ˆæ­¤åˆ—è¡¨ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°è®¸å¤šè¯­è¨€éƒ½å­˜åœ¨ï¼Œä½†è¿ªç»´å¸Œè¯­æ˜¯å°‘æ•°ä¸å­˜åœ¨çš„ä¹‹ä¸€ï¼è¿™æ„å‘³ç€ Whisper æ²¡æœ‰åœ¨è¿ªç»´å¸Œè¯­ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚
ç„¶è€Œï¼Œè¿™å¹¶ä¸æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½åœ¨å…¶ä¸Šå¾®è°ƒ Whisperã€‚è¿™æ ·åšï¼Œæˆ‘ä»¬å°†æ•™ä¼š Whisper ä¸€ç§æ–°çš„è¯­è¨€ï¼Œä¸€ç§é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ä¸æ”¯æŒçš„è¯­è¨€ã€‚è¿™å¾ˆé…·ï¼Œå¯¹å§ï¼

å½“æ‚¨åœ¨ä¸€ç§æ–°è¯­è¨€ä¸Šå¾®è°ƒæ—¶ï¼ŒWhisper å¯ä»¥åˆ©ç”¨å®ƒåœ¨å…¶ä»– 96 ç§è¯­è¨€ä¸Šçš„é¢„è®­ç»ƒçŸ¥è¯†ã€‚æ€»çš„æ¥è¯´ï¼Œæ‰€æœ‰ç°ä»£è¯­è¨€åœ¨è¯­è¨€å­¦ä¸Šè‡³å°‘ä¸ Whisper å·²ç»
çŸ¥é“çš„ 96 ç§è¯­è¨€ä¸­çš„ä¸€ç§ç±»ä¼¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åˆ©ç”¨èµ·è¿™ç§è·¨è¯­è¨€çš„çŸ¥è¯†ã€‚

æˆ‘ä»¬éœ€è¦åšçš„æ˜¯æ‰¾åˆ° Whisper åœ¨é¢„è®­ç»ƒæœŸé—´å­¦ä¹ è¿‡**æœ€ç›¸ä¼¼**çš„è¯­è¨€ã€‚ç»´åŸºç™¾ç§‘çš„è¿ªç»´å¸Œè¯­è¯æ¡æŒ‡å‡ºï¼Œè¿ªç»´å¸Œè¯­ä¸æ–¯é‡Œå…°å¡çš„åƒ§ä¼½ç½—è¯­å¯†åˆ‡ç›¸å…³ã€‚
å¦‚æœæˆ‘ä»¬å†æ¬¡æ£€æŸ¥è¯­è¨€ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åƒ§ä¼½ç½—è¯­å­˜åœ¨äº Whisper è¯­è¨€é›†ä¸­ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°å°†æˆ‘ä»¬çš„è¯­è¨€å‚æ•°è®¾ç½®ä¸º `"sinhalese"`ã€‚

å¥½ï¼æˆ‘ä»¬å°†ä»é¢„è®­ç»ƒæ£€æŸ¥ç‚¹åŠ è½½æˆ‘ä»¬çš„å¤„ç†å™¨ï¼Œå°†è¯­è¨€è®¾ç½®ä¸º `"sinhalese"`ï¼Œä»»åŠ¡è®¾ç½®ä¸º `"transcribe"`ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼š

```python
from transformers import WhisperProcessor

processor = WhisperProcessor.from_pretrained(
    "openai/whisper-small", language="sinhalese", task="transcribe"
)
```

å€¼å¾—é‡ç”³çš„æ˜¯ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨ä¼šå‘ç°æ‚¨æƒ³è¦å¾®è°ƒçš„è¯­è¨€åœ¨é¢„è®­ç»ƒè¯­è¨€é›†ä¸­ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥ç›´æ¥å°†è¯­è¨€è®¾ç½®ä¸ºæ‚¨çš„æºéŸ³é¢‘è¯­è¨€ï¼
è¯·æ³¨æ„ï¼Œå¯¹äºä»…è‹±è¯­çš„å¾®è°ƒï¼Œè¿™ä¸¤ä¸ªå‚æ•°åº”çœç•¥ï¼Œè¿™ç§æƒ…å†µä¸‹è¯­è¨€ï¼ˆ`"English"`ï¼‰å’Œä»»åŠ¡ï¼ˆ`"transcribe"`ï¼‰éƒ½æ˜¯å”¯ä¸€é»˜è®¤çš„é€‰é¡¹ã€‚

## é¢„å¤„ç†æ•°æ®

è®©æˆ‘ä»¬çœ‹çœ‹æ•°æ®é›†ç‰¹å¾ã€‚ç‰¹åˆ«æ³¨æ„ `"audio"` åˆ—â€”â€”è¿™è¯¦ç»†è¯´æ˜äº†æˆ‘ä»¬è¾“å…¥éŸ³é¢‘çš„é‡‡æ ·ç‡ï¼š

```python
common_voice["train"].features
```

**è¾“å‡ºï¼š**

```
{'audio': Audio(sampling_rate=48000, mono=True, decode=True, id=None),
 'sentence': Value(dtype='string', id=None)}
```

ç”±äºæˆ‘ä»¬çš„è¾“å…¥éŸ³é¢‘é‡‡æ ·ç‡ä¸º 48kHzï¼Œæˆ‘ä»¬éœ€è¦åœ¨å°†å…¶ä¼ é€’ç»™ Whisper ç‰¹å¾æå–å™¨ä¹‹å‰å°†å…¶ _ä¸‹é‡‡æ ·_ åˆ° 16kHzï¼Œ16kHz æ˜¯ Whisper æ¨¡å‹æœŸæœ›çš„é‡‡æ ·ç‡ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨æ•°æ®é›†çš„ [`cast_column`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.cast_column) æ–¹æ³•
å°†éŸ³é¢‘è¾“å…¥è®¾ç½®ä¸ºæ­£ç¡®çš„é‡‡æ ·ç‡ã€‚æ­¤æ“ä½œä¸ä¼šå°±åœ°æ›´æ”¹éŸ³é¢‘ï¼Œè€Œæ˜¯æŒ‡ç¤ºæ•°æ®é›†åœ¨åŠ è½½éŸ³é¢‘æ ·æœ¬æ—¶å³æ—¶åœ°é‡é‡‡æ ·ï¼š

```python
from datasets import Audio

sampling_rate = processor.feature_extractor.sampling_rate
common_voice = common_voice.cast_column("audio", Audio(sampling_rate=sampling_rate))
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸€ä¸ªå‡½æ•°æ¥å‡†å¤‡æˆ‘ä»¬çš„æ•°æ®ä»¥ä¾›æ¨¡å‹ä½¿ç”¨ï¼š

1. è°ƒç”¨ `sample["audio"]` åœ¨é€ä¸ªæ ·æœ¬ä¸ŠåŠ è½½å’Œé‡é‡‡æ ·éŸ³é¢‘æ•°æ®ã€‚å¦‚ä¸Šæ‰€è¿°ï¼ŒğŸ¤— Datasets åœ¨åŠ è½½æ—¶å³æ—¶æ‰§è¡Œä»»ä½•å¿…è¦çš„é‡é‡‡æ ·æ“ä½œã€‚
2. ç”¨ç‰¹å¾æå–å™¨ä»æˆ‘ä»¬çš„ä¸€ç»´éŸ³é¢‘æ•°ç»„è®¡ç®— log-mel é¢‘è°±å›¾è¾“å…¥ç‰¹å¾ã€‚
3. ç”¨åˆ†è¯å™¨å°†è½¬å†™æ–‡æœ¬ç¼–ç ä¸ºæ ‡ç­¾ idã€‚

```python
def prepare_dataset(example):
    audio = example["audio"]

    example = processor(
        audio=audio["array"],
        sampling_rate=audio["sampling_rate"],
        text=example["sentence"],
    )

    # è®¡ç®—è¾“å…¥éŸ³é¢‘æ ·æœ¬çš„é•¿åº¦ï¼Œä»¥ç§’è®¡
    example["input_length"] = len(audio["array"]) / audio["sampling_rate"]

    return example
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ ğŸ¤— Datasets çš„ `.map` æ–¹æ³•å°†æ•°æ®é¢„å¤„ç†å‡½æ•°åº”ç”¨äºæˆ‘ä»¬æ‰€æœ‰çš„è®­ç»ƒæ ·æœ¬ã€‚
æˆ‘ä»¬å°†ä»åŸå§‹è®­ç»ƒæ•°æ®ä¸­ç§»é™¤åŸæœ‰çš„åˆ—ï¼ˆéŸ³é¢‘å’Œæ–‡æœ¬ï¼‰ï¼Œåªç•™ä¸‹ `prepare_dataset` å‡½æ•°è¿”å›çš„åˆ—ï¼š

```python
common_voice = common_voice.map(
    prepare_dataset, remove_columns=common_voice.column_names["train"], num_proc=1
)
```
æœ€åï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è¿‡æ»¤æ‰éŸ³é¢‘æ ·æœ¬é•¿åº¦è¶…è¿‡ 30s çš„è®­ç»ƒæ•°æ®ã€‚è¿™äº›æ ·æœ¬å¦åˆ™ä¼šè¢« Whisper ç‰¹å¾æå–å™¨æˆªæ–­ï¼Œè¿™å¯èƒ½å½±å“è®­ç»ƒçš„ç¨³å®šæ€§ã€‚
æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå¯¹äºå°äº 30s çš„æ ·æœ¬è¿”å› `True`ï¼Œå¯¹äºæ›´é•¿çš„æ ·æœ¬è¿”å› `False`ï¼š

```python
max_input_length = 30.0


def is_audio_in_length_range(length):
    return length < max_input_length
```

æˆ‘ä»¬é€šè¿‡ ğŸ¤— Datasets çš„ `.filter` æ–¹æ³•å°†æˆ‘ä»¬çš„è¿‡æ»¤å‡½æ•°åº”ç”¨äºæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†çš„æ‰€æœ‰æ ·æœ¬ï¼š

```python
common_voice["train"] = common_voice["train"].filter(
    is_audio_in_length_range,
    input_columns=["input_length"],
)
```

è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹é€šè¿‡è¿™ä¸ªè¿‡æ»¤æ­¥éª¤æˆ‘ä»¬ç§»é™¤äº†å¤šå°‘è®­ç»ƒæ•°æ®ï¼š

```python
common_voice["train"]
```

**è¾“å‡ºï¼š**

```
Dataset({
    features: ['input_features', 'labels', 'input_length'],
    num_rows: 4904
})
```

å¥½çš„ï¼åœ¨è¿‡æ»¤å‰åæˆ‘ä»¬æœ‰ç›¸åŒæ•°é‡çš„æ ·æœ¬ï¼Œæ‰€ä»¥åŸæ•°æ®é›†ä¸­æ²¡æœ‰è¶…è¿‡ 30s çš„æ ·æœ¬ã€‚å¦‚æœæ‚¨åˆ‡æ¢è¯­è¨€ï¼Œæƒ…å†µå¯èƒ½ä¸åŒï¼Œå› æ­¤ä¸ºäº†ç¨³å¥æ€§æœ€å¥½ä¿ç•™è¿™ä¸ªè¿‡æ»¤æ­¥éª¤ã€‚
æœ‰äº†è¿™äº›ï¼Œæˆ‘ä»¬çš„æ•°æ®å·²ç»å®Œå…¨å‡†å¤‡å¥½è¿›è¡Œè®­ç»ƒäº†ï¼è®©æˆ‘ä»¬ç»§ç»­çœ‹çœ‹å¦‚ä½•ä½¿ç”¨è¿™äº›æ•°æ®æ¥å¾®è°ƒ Whisperã€‚

## è®­ç»ƒå’Œè¯„ä¼°

ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æˆ‘ä»¬çš„æ•°æ®ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½æ·±å…¥è®­ç»ƒæµç¨‹äº†ã€‚
[ğŸ¤— Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer) å°†ä¸ºæˆ‘ä»¬å®Œæˆå¤§éƒ¨åˆ†ç¹é‡çš„å·¥ä½œã€‚æˆ‘ä»¬æ‰€è¦åšçš„å°±æ˜¯ï¼š

- å®šä¹‰ä¸€ä¸ªæ•°æ®æ•´ç†å™¨ï¼šæ•°æ®æ•´ç†å™¨æ¥å—æˆ‘ä»¬é¢„å¤„ç†çš„æ•°æ®å¹¶å‡†å¤‡å¥½ PyTorch å¼ é‡ä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚
- è¯„ä¼°æŒ‡æ ‡ï¼šæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨è¯é”™è¯¯ç‡ï¼ˆWERï¼‰æŒ‡æ ‡æ¥è¯„ä¼°æ¨¡å‹ï¼Œéœ€è¦å®šä¹‰ä¸€ä¸ªå¤„ç†è¿™ç§è®¡ç®—çš„ `compute_metrics` å‡½æ•°ã€‚
- åŠ è½½é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ï¼šæˆ‘ä»¬éœ€è¦åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ£€æŸ¥ç‚¹å¹¶ä¸ºè®­ç»ƒæ­£ç¡®é…ç½®å®ƒã€‚
- å®šä¹‰è®­ç»ƒå‚æ•°ï¼šè¿™å°†è¢« ğŸ¤— Trainer ç”¨æ¥æ„å»ºè®­ç»ƒè®¡åˆ’ã€‚

ä¸€æ—¦æˆ‘ä»¬å®Œæˆäº†æ¨¡å‹çš„å¾®è°ƒï¼Œæˆ‘ä»¬å°†åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°å®ƒï¼Œä»¥éªŒè¯æˆ‘ä»¬æ˜¯å¦æ­£ç¡®åœ°è®­ç»ƒäº†å®ƒè½¬å†™è¿ªç»´å¸Œè¯­è¯­éŸ³ã€‚

### å®šä¹‰æ•°æ®æ•´ç†å™¨

åºåˆ—åˆ°åºåˆ—è¯­éŸ³æ¨¡å‹çš„æ•°æ®æ•´ç†å™¨å¾ˆç‹¬ç‰¹ï¼Œå®ƒèƒ½ç‹¬ç«‹åœ°å¤„ç† `input_features` å’Œ `labels`ï¼š`input_features` å¿…é¡»ç”±ç‰¹å¾æå–å™¨å¤„ç†ï¼Œè€Œ `labels` ç”±åˆ†è¯å™¨å¤„ç†ã€‚

`input_features` å·²ç»å¡«å……åˆ° 30s å¹¶è½¬æ¢ä¸ºå›ºå®šç»´åº¦çš„ log-Mel é¢‘è°±å›¾ï¼Œæ‰€ä»¥æˆ‘ä»¬æ‰€è¦åšçš„å°±æ˜¯ä½¿ç”¨ç‰¹å¾æå–å™¨çš„ `.pad` æ–¹æ³•ï¼Œ
å¹¶è®¾ç½®å‚æ•° `return_tensors=pt`ï¼Œå°†å®ƒä»¬è½¬æ¢ä¸ºæ‰¹é‡çš„ PyTorch å¼ é‡ã€‚è¯·æ³¨æ„ï¼Œè¿™é‡Œæ²¡æœ‰åº”ç”¨é¢å¤–çš„å¡«å……ï¼Œå› ä¸ºè¾“å…¥æ˜¯å›ºå®šç»´åº¦çš„ï¼Œ
`input_features` ä»…è¢«è½¬æ¢ä¸º PyTorch å¼ é‡ã€‚

å¦ä¸€æ–¹é¢ï¼Œ`labels` æ˜¯æœªå¡«å……çš„ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨åˆ†è¯å™¨çš„ `.pad` æ–¹æ³•å°†åºåˆ—å¡«å……åˆ°æ‰¹æ¬¡ä¸­çš„æœ€å¤§é•¿åº¦ã€‚ç„¶åç”¨ `-100` æ›¿æ¢å¡«å……è¯å…ƒï¼Œ
ä»¥ä¾¿åœ¨è®¡ç®—æŸå¤±å‡½æ•°æ—¶**ä¸**è€ƒè™‘è¿™äº›è¯å…ƒã€‚æˆ‘ä»¬è¿˜è¦å»æ‰æ ‡ç­¾åºåˆ—å¼€å¤´çš„è½¬å†™èµ·å§‹ï¼ˆstart of transcriptï¼‰è¯å…ƒï¼Œå› ä¸ºæˆ‘ä»¬ç¨ååœ¨è®­ç»ƒæœŸé—´ä¼šæ·»åŠ å®ƒã€‚

æˆ‘ä»¬å¯ä»¥åˆ©ç”¨æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„ `WhisperProcessor` æ¥æ‰§è¡Œç‰¹å¾æå–å™¨å’Œåˆ†è¯å™¨æ“ä½œï¼š

```python
import torch

from dataclasses import dataclass
from typing import Any, Dict, List, Union


@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        # åˆ†ç¦»è¾“å…¥ç‰¹å¾å’Œæ ‡ç­¾ï¼Œå®ƒä»¬é•¿åº¦ä¸åŒï¼Œå¡«å……æ–¹å¼ä¹Ÿä¸åŒ
        # é¦–å…ˆä»¥ PyTorch å¼ é‡æ ¼å¼è¿”å›éŸ³é¢‘
        input_features = [
            {"input_features": feature["input_features"][0]} for feature in features
        ]
        batch = self.processor.feature_extractor.pad(input_features, return_tensors="pt")

        # è·å–åˆ†è¯åå¾—åˆ°çš„æ ‡ç­¾åºåˆ—
        label_features = [{"input_ids": feature["labels"]} for feature in features]
        # æŠŠæ ‡ç­¾åºåˆ—å¡«å……åˆ°æœ€å¤§é•¿åº¦
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")

        # ç”¨ -100 æ¥ä»£æ›¿å¡«å……è¿›çš„æ ‡ç­¾ï¼Œä»è€Œä¸å½±å“æŸå¤±å‡½æ•°çš„è®¡ç®—
        labels = labels_batch["input_ids"].masked_fill(
            labels_batch.attention_mask.ne(1), -100
        )

        # å¦‚æœåœ¨ä¹‹å‰åˆ†è¯æ—¶æ·»åŠ äº† bos è¯å…ƒï¼Œé‚£å°±å‰ªåˆ‡æ‰ï¼Œå› ä¸ºä¹‹åè¿˜ä¼šåŠ ä¸Šçš„
        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():
            labels = labels[:, 1:]

        batch["labels"] = labels

        return batch
```

æˆ‘ä»¬ç°åœ¨å¯ä»¥åˆå§‹åŒ–æˆ‘ä»¬åˆšåˆšå®šä¹‰çš„æ•°æ®æ•´ç†å™¨ï¼š

```python
data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)
```

ç»§ç»­ï¼

### è¯„ä¼°æŒ‡æ ‡

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬åœ¨æµ‹è¯•é›†ä¸Šå°†ä½¿ç”¨çš„è¯„ä¼°æŒ‡æ ‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [è¯„ä»·æŒ‡æ ‡](evaluation) ç« èŠ‚ä¸­ä»‹ç»çš„è¯é”™è¯¯ç‡ï¼ˆWERï¼‰æŒ‡æ ‡ï¼Œè¿™æ˜¯è¯„ä¼° ASR ç³»ç»Ÿçš„â€œäº‹å®ä¸Šâ€çš„æŒ‡æ ‡ã€‚

æˆ‘ä»¬ä» ğŸ¤— Evaluate åŠ è½½ WER æŒ‡æ ‡ï¼š

```python
import evaluate

metric = evaluate.load("wer")
```

ç„¶åæˆ‘ä»¬åªéœ€å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒæ¥å—æˆ‘ä»¬æ¨¡å‹çš„é¢„æµ‹å¹¶è¿”å› WER æŒ‡æ ‡ã€‚è¿™ä¸ªå‡½æ•°ç§°ä¸º `compute_metrics`ï¼Œé¦–å…ˆç”¨ `pad_token_id` æ›¿æ¢ `label_ids` ä¸­çš„ `-100`
ï¼ˆæ’¤é”€æˆ‘ä»¬åœ¨æ•°æ®æ•´ç†å™¨ä¸­ä¸ºäº†åœ¨æŸå¤±å‡½æ•°ä¸­æ­£ç¡®å¿½ç•¥å¡«å……è¯å…ƒåšçš„æ­¥éª¤ï¼‰ã€‚ç„¶åï¼Œå®ƒå°†é¢„æµ‹çš„æ ‡ç­¾ id è§£ç ä¸ºå­—ç¬¦ä¸²ã€‚æœ€åï¼Œå®ƒè®¡ç®—é¢„æµ‹ç»“æœå’Œå‚è€ƒæ ‡ç­¾ä¹‹é—´çš„ WERã€‚
åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©è¯„ä¼°â€œæ ‡å‡†åŒ–â€çš„è½¬å½•å’Œé¢„æµ‹ï¼Œè¿™äº›è½¬å½•å’Œé¢„æµ‹éƒ½ç§»é™¤äº†æ ‡ç‚¹å’Œå¤§å°å†™ã€‚æˆ‘ä»¬å»ºè®®æ‚¨éµå¾ªè¿™ä¸ªæ­¥éª¤ï¼Œé€šè¿‡æ ‡å‡†åŒ–è½¬å½•æ”¹è¿› WERã€‚

```python
from transformers.models.whisper.english_normalizer import BasicTextNormalizer

normalizer = BasicTextNormalizer()


def compute_metrics(pred):
    pred_ids = pred.predictions
    label_ids = pred.label_ids

    # ç”¨ pad_token_id æ›¿æ¢ -100
    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id

    # æˆ‘ä»¬å¸Œæœ›åœ¨è®¡ç®—æŒ‡æ ‡æ—¶ä¸è¦ç»„åˆèµ·è¯å…ƒ
    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)
    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)

    # è®¡ç®—æ™®é€šçš„ WER
    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)

    # è®¡ç®—æ ‡å‡†åŒ–çš„ WER
    pred_str_norm = [normalizer(pred) for pred in pred_str]
    label_str_norm = [normalizer(label) for label in label_str]
    # è¿‡æ»¤ï¼Œä»è€Œåœ¨è¯„ä¼°æ—¶åªè®¡ç®— reference éç©ºçš„æ ·æœ¬
    pred_str_norm = [
        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0
    ]
    label_str_norm = [
        label_str_norm[i]
        for i in range(len(label_str_norm))
        if len(label_str_norm[i]) > 0
    ]

    wer = 100 * metric.compute(predictions=pred_str_norm, references=label_str_norm)

    return {"wer_ortho": wer_ortho, "wer": wer}
```

### åŠ è½½é¢„è®­ç»ƒæ£€æŸ¥ç‚¹

ç°åœ¨è®©æˆ‘ä»¬åŠ è½½é¢„è®­ç»ƒçš„ Whisper small æ£€æŸ¥ç‚¹ã€‚ç”¨ ğŸ¤— Transformers è¿™æ˜¯å°èœä¸€ç¢Ÿï¼

```python
from transformers import WhisperForConditionalGeneration

model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
```

æˆ‘ä»¬å°† `use_cache` è®¾ç½®ä¸º `False` ä»¥è¿›è¡Œè®­ç»ƒï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨ [æ¢¯åº¦æ£€æŸ¥ç‚¹](https://huggingface.co/docs/transformers/v4.18.0/en/performance#gradient-checkpointing)ï¼Œ
ä¸¤è€…ä¸å…¼å®¹ã€‚æˆ‘ä»¬è¿˜å°†è¦†ç›–ä¸¤ä¸ªç”Ÿæˆå‚æ•°ä»¥æ§åˆ¶æ¨¡å‹åœ¨æ¨ç†æœŸé—´çš„è¡Œä¸ºï¼šæˆ‘ä»¬å°†é€šè¿‡è®¾ç½® `language` å’Œ `task` å‚æ•°åœ¨ç”ŸæˆæœŸé—´å¼ºåˆ¶è§„å®šè¯­è¨€å’Œä»»åŠ¡æ ‡ç­¾ï¼Œ
å¹¶é‡æ–°å¯ç”¨ç¼“å­˜ä»¥åŠ é€Ÿæ¨ç†ï¼š

```python
from functools import partial

# åœ¨è®­ç»ƒæœŸé—´ä¸ä½¿ç”¨ç¼“å­˜ï¼Œå› ä¸ºå®ƒå’Œæ¢¯åº¦æ£€æŸ¥ç‚¹ä¸å…¼å®¹
model.config.use_cache = False

# ä¸ºç”Ÿæˆè®¾ç½®è¯­è¨€å’Œä»»åŠ¡ï¼Œå¹¶é‡æ–°å¯ç”¨ç¼“å­˜
model.generate = partial(
    model.generate, language="sinhalese", task="transcribe", use_cache=True
)
```

## å®šä¹‰è®­ç»ƒé…ç½®

åœ¨æœ€åä¸€æ­¥ï¼Œæˆ‘ä»¬å®šä¹‰äº†æ‰€æœ‰ä¸è®­ç»ƒç›¸å…³çš„å‚æ•°ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è®­ç»ƒæ­¥éª¤æ•°è®¾ç½®ä¸º 500ã€‚è¿™è¶³ä»¥çœ‹åˆ°ä¸é¢„è®­ç»ƒ Whisper æ¨¡å‹ç›¸æ¯” WER å¤§å¹…æå‡ï¼Œ
åŒæ—¶ç¡®ä¿å¾®è°ƒå¯ä»¥åœ¨å¤§çº¦ 45 åˆ†é’Ÿå†…åœ¨ Google Colab å…è´¹ç‰ˆä¸Šè¿è¡Œå®Œã€‚æœ‰å…³è®­ç»ƒå‚æ•°çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜… Seq2SeqTrainingArguments [æ–‡æ¡£](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)ã€‚

```python
from transformers import Seq2SeqTrainingArguments

training_args = Seq2SeqTrainingArguments(
    output_dir="./whisper-small-dv",  # åœ¨ HF Hub ä¸Šçš„è¾“å‡ºç›®å½•çš„åå­—
    per_device_train_batch_size=16,
    gradient_accumulation_steps=1,  # æ¯æ¬¡ batch size ä¸‹è°ƒåˆ°ä¸€åŠå°±æŠŠè¿™ä¸ªå‚æ•°ä¸Šè°ƒåˆ°ä¸¤å€
    learning_rate=1e-5,
    lr_scheduler_type="constant_with_warmup",
    warmup_steps=50,
    max_steps=500,  # å¦‚æœæ‚¨æœ‰è‡ªå·±çš„ GPU æˆ–è€… Colab ä»˜è´¹è®¡åˆ’ï¼Œä¸Šè°ƒåˆ° 4000
    gradient_checkpointing=True,
    fp16=True,
    fp16_full_eval=True,
    evaluation_strategy="steps",
    per_device_eval_batch_size=16,
    predict_with_generate=True,
    generation_max_length=225,
    save_steps=500,
    eval_steps=500,
    logging_steps=25,
    report_to=["tensorboard"],
    load_best_model_at_end=True,
    metric_for_best_model="wer",
    greater_is_better=False,
    push_to_hub=True,
)
```

<Tip>
    å¦‚æœæ‚¨ä¸æƒ³å°†æ¨¡å‹æ£€æŸ¥ç‚¹ä¸Šä¼ åˆ° Hubï¼Œè¯·è®¾ç½® `push_to_hub=False`ã€‚
</Tip>

æˆ‘ä»¬å¯ä»¥å°†è®­ç»ƒå‚æ•°ä¼ é€’ç»™ ğŸ¤— Trainerï¼Œè¿åŒæˆ‘ä»¬çš„æ¨¡å‹ã€æ•°æ®é›†ã€æ•°æ®æ•´ç†å™¨å’Œ `compute_metrics` å‡½æ•°ä¸€èµ·ï¼š

```python
from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    args=training_args,
    model=model,
    train_dataset=common_voice["train"],
    eval_dataset=common_voice["test"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=processor,
)
```

æœ‰äº†è¿™ä¸ªï¼Œæˆ‘ä»¬å°±å‡†å¤‡å¥½å¼€å§‹è®­ç»ƒäº†ï¼

### è®­ç»ƒ

è¦å¯åŠ¨è®­ç»ƒï¼Œåªéœ€æ‰§è¡Œï¼š

```python
trainer.train()
```

è®­ç»ƒå¤§çº¦éœ€è¦ 45 åˆ†é’Ÿï¼Œå–å†³äºæ‚¨çš„ GPU æˆ– Google Colab ç»™åˆ†é…çš„ GPU ã€‚ç”±äº GPU ä¸åŒï¼Œå½“æ‚¨å¼€å§‹è®­ç»ƒæ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ° CUDA `"out-of-memory"` é”™è¯¯ã€‚
åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥ä¸¤å€ä¸¤å€åœ°é€æ¸å‡å°‘ `per_device_train_batch_size` å¹¶ä½¿ç”¨ [`gradient_accumulation_steps`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments.gradient_accumulation_steps) æ¥è¡¥å¿ã€‚

**è¾“å‡ºï¼š**

| Training Loss | Epoch | Step | Validation Loss | Wer Ortho | Wer     |
|:-------------:|:-----:|:----:|:---------------:|:---------:|:-------:|
| 0.136         | 1.63  | 500  | 0.1727          | 63.8972   | 14.0661 |

æˆ‘ä»¬æœ€ç»ˆçš„ WER æ˜¯ 14.1%â€”â€”å¯¹äºä¸ƒå°æ—¶çš„è®­ç»ƒæ•°æ®å’Œä»… 500 è®­ç»ƒæ­¥éª¤æ¥è¯´ä¸é”™ï¼Œè¿™ç›¸å½“äºä¸é¢„è®­ç»ƒæ¨¡å‹ç›¸æ¯”æé«˜äº† 112%ï¼
è¿™æ„å‘³ç€æˆ‘ä»¬å·²ç»å°†ä¸€ä¸ªä¹‹å‰ä¸äº†è§£è¿ªç»´å¸Œè¯­çš„æ¨¡å‹å¾®è°ƒä¸ºåœ¨ä¸åˆ°ä¸€å°æ—¶å†…ä»¥è¶³å¤Ÿçš„å‡†ç¡®æ€§è¯†åˆ«è¿ªç»´å¸Œè¯­è¯­éŸ³ ğŸ¤¯

æœ€é‡è¦çš„æ˜¯ï¼Œè¿™ä¸å…¶ä»– ASR ç³»ç»Ÿç›¸æ¯”å¦‚ä½•ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ autoevaluate [æ’è¡Œæ¦œ](https://huggingface.co/spaces/autoevaluate/leaderboards?dataset=mozilla-foundation%2Fcommon_voice_13_0&only_verified=0&task=automatic-speech-recognition&config=dv&split=test&metric=wer)ï¼Œ
ä¸€ä¸ªæ ¹æ®è¯­è¨€å’Œæ•°æ®é›†åˆ†ç±»æ¨¡å‹å¹¶æ ¹æ®å®ƒä»¬çš„ WER æ’åçš„æ’è¡Œæ¦œã€‚

æŸ¥çœ‹æ’è¡Œæ¦œï¼Œæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬è®­ç»ƒäº† 500 æ­¥çš„æ¨¡å‹ä»¤äººä¿¡æœåœ°å‡»è´¥äº†æˆ‘ä»¬åœ¨å‰ä¸€èŠ‚è¯„ä¼°çš„é¢„è®­ç»ƒ [Whisper Small](https://huggingface.co/openai/whisper-small) æ£€æŸ¥ç‚¹ã€‚å¹²å¾—å¥½ ğŸ‘

æˆ‘ä»¬çœ‹åˆ°æœ‰ä¸€äº›æ£€æŸ¥ç‚¹æ¯”æˆ‘ä»¬è®­ç»ƒçš„è¡¨ç°æ›´å¥½ã€‚Hugging Face Hub çš„ç¾å¦™ä¹‹å¤„åœ¨äºå®ƒæ˜¯ä¸€ä¸ª*åä½œ*å¹³å°â€”â€”å¦‚æœæˆ‘ä»¬æ²¡æœ‰æ—¶é—´æˆ–èµ„æºè‡ªå·±è¿›è¡Œæ›´é•¿æ—¶é—´çš„è®­ç»ƒè¿è¡Œï¼Œ
æˆ‘ä»¬å¯ä»¥åŠ è½½ç¤¾åŒºä¸­å…¶ä»–äººå·²ç»è®­ç»ƒå¹¶æ…·æ…¨åˆ†äº«çš„æ£€æŸ¥ç‚¹ï¼ˆè®°å¾—å¯¹ä»–ä»¬å¿ƒæ€€æ„Ÿè°¢ï¼ï¼‰ã€‚æ‚¨å°†èƒ½å¤Ÿä»¥ä¸é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ç›¸åŒçš„æ–¹å¼ä½¿ç”¨ `pipeline` ç±»åŠ è½½è¿™äº›æ£€æŸ¥ç‚¹ï¼Œ
æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€åšçš„ï¼æ‰€ä»¥æ²¡æœ‰ä»€ä¹ˆèƒ½é˜»æ­¢æ‚¨æŒ‘é€‰æ’è¡Œæ¦œä¸Šæœ€ä½³æ¨¡å‹æ¥ç”¨äºæ‚¨çš„ä»»åŠ¡ï¼

æˆ‘ä»¬å¯ä»¥åœ¨å°†è®­ç»ƒç»“æœæ¨é€åˆ° Hub æ—¶è‡ªåŠ¨å°†æˆ‘ä»¬çš„æ£€æŸ¥ç‚¹æäº¤åˆ°æ’è¡Œæ¦œâ€”â€”æˆ‘ä»¬åªéœ€è®¾ç½®é€‚å½“çš„å…³é”®å­—å‚æ•° (kwargs)ã€‚æ‚¨å¯ä»¥æ ¹æ®æ‚¨çš„æ•°æ®é›†ã€è¯­è¨€å’Œæ¨¡å‹åç§°ç›¸åº”åœ°æ›´æ”¹è¿™äº›å€¼ï¼š

```python
kwargs = {
    "dataset_tags": "mozilla-foundation/common_voice_13_0",
    "dataset": "Common Voice 13",  # è®­ç»ƒæ•°æ®é›†
    "language": "dv",
    "model_name": "Whisper Small Dv - Sanchit Gandhi",  # ç»™æ¨¡å‹èµ·ä¸ªâ€œæ¼‚äº®â€çš„åå­—
    "finetuned_from": "openai/whisper-small",
    "tasks": "automatic-speech-recognition",
}
```

ç°åœ¨å¯ä»¥å°†è®­ç»ƒç»“æœä¸Šä¼ åˆ° Hubï¼Œè¯·æ‰§è¡Œ `push_to_hub` å‘½ä»¤ï¼š

```python
trainer.push_to_hub(**kwargs)
```

è¿™å°†åœ¨ `"æ‚¨çš„ç”¨æˆ·å/æ‚¨ç»™æ¨¡å‹èµ·çš„åå­—"` ä¸‹ä¿å­˜è®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹æƒé‡ã€‚ä½œä¸ºç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹ `sanchit-gandhi/whisper-small-dv` ä¸Šçš„ä¸Šä¼ æ–‡ä»¶ã€‚

è™½ç„¶åœ¨ Common Voice 13 è¿ªç»´å¸Œè¯­æµ‹è¯•æ•°æ®ä¸Šå¾®è°ƒçš„æ¨¡å‹æä¾›äº†ä»¤äººæ»¡æ„çš„ç»“æœï¼Œä½†è¿™ç»éæœ€ä½³ã€‚æœ¬æŒ‡å—çš„ç›®çš„æ˜¯æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ ğŸ¤— Trainer å¾®è°ƒ ASR æ¨¡å‹ä»¥è¿›è¡Œå¤šè¯­è¨€è¯­éŸ³è¯†åˆ«ã€‚

å¦‚æœæ‚¨æœ‰è‡ªå·±çš„ GPU æˆ–è®¢é˜…äº† Google Colab ä»˜è´¹è®¡åˆ’ï¼Œæ‚¨å¯ä»¥å°† `max_steps` å¢åŠ åˆ° 4000 æ­¥ï¼Œé€šè¿‡æ›´å¤šæ­¥éª¤çš„è®­ç»ƒè¿›ä¸€æ­¥é™ä½å¤§çº¦ 3% çš„ WERã€‚
å¦‚æœæ‚¨å†³å®šè¿›è¡Œ 4000 æ­¥çš„è®­ç»ƒï¼Œæˆ‘ä»¬è¿˜å»ºè®®å°†å­¦ä¹ ç‡è°ƒåº¦å™¨æ›´æ”¹ä¸º*çº¿æ€§*è®¡åˆ’ï¼ˆè®¾ç½® `lr_scheduler_type="linear"`ï¼‰ï¼Œå› ä¸ºè¿™å°†åœ¨é•¿æ—¶é—´çš„è®­ç»ƒä¸­æå‡æ›´å¤šæ€§èƒ½ã€‚

é€šè¿‡ä¼˜åŒ–è®­ç»ƒè¶…å‚æ•°ï¼Œå¦‚ _å­¦ä¹ ç‡_ å’Œ _dropout_ï¼Œå¹¶ä½¿ç”¨æ›´å¤§çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆ`medium` æˆ– `large`ï¼‰ï¼Œå¯èƒ½è¿›ä¸€æ­¥æ”¹å–„ç»“æœã€‚æˆ‘ä»¬å°†è¿™ç•™ä½œè¯»è€…çš„ç»ƒä¹ ã€‚

## åˆ†äº«æ‚¨çš„æ¨¡å‹

æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨ Hub ä¸Šçš„é“¾æ¥ä¸ä»»ä½•äººå…±äº«æ­¤æ¨¡å‹ã€‚å¤§å®¶å¯ä»¥ç›´æ¥å°†æ ‡è¯†ç¬¦ `"æ‚¨çš„ç”¨æˆ·å/æ‚¨ç»™æ¨¡å‹èµ·çš„åå­—"` åŠ è½½åˆ° `pipeline()` å¯¹è±¡ä¸­ã€‚
ä¾‹å¦‚ï¼Œè¦åŠ è½½å¾®è°ƒçš„æ£€æŸ¥ç‚¹ ["sanchit-gandhi/whisper-small-dv"](https://huggingface.co/sanchit-gandhi/whisper-small-dv)ï¼š

```python
from transformers import pipeline

pipe = pipeline("automatic-speech-recognition", model="sanchit-gandhi/whisper-small-dv")
```

## ç»“è®º

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬é€æ­¥ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ ğŸ¤— Datasetsã€Transformers å’Œ Hugging Face Hub å¾®è°ƒ Whisper æ¨¡å‹ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«ã€‚
æˆ‘ä»¬é¦–å…ˆåŠ è½½äº† Common Voice 13 æ•°æ®é›†çš„è¿ªç»´å¸Œè¯­å­é›†ï¼Œå¹¶é€šè¿‡è®¡ç®— log-mel é¢‘è°±å›¾å’Œåˆ†è¯æ–‡æœ¬å¯¹å…¶è¿›è¡Œäº†é¢„å¤„ç†ã€‚ç„¶åæˆ‘ä»¬å®šä¹‰äº†æ•°æ®æ•´ç†å™¨ã€è¯„ä¼°æŒ‡æ ‡å’Œè®­ç»ƒå‚æ•°ï¼Œ
ä½¿ç”¨ ğŸ¤— Trainer æ¥è®­ç»ƒå’Œè¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†å¾®è°ƒçš„æ¨¡å‹ä¸Šä¼ åˆ° Hugging Face Hubï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `pipeline()` ç±»å…±äº«å’Œä½¿ç”¨å®ƒã€‚

å¦‚æœæ‚¨ä¸€ç›´å­¦åˆ°äº†è¿™é‡Œï¼Œæ‚¨ç°åœ¨åº”è¯¥æœ‰äº†ä¸€ä¸ªç”¨äºè¯­éŸ³è¯†åˆ«çš„å¾®è°ƒæ£€æŸ¥ç‚¹ï¼Œå¹²å¾—å¥½ï¼ğŸ¥³ æ›´é‡è¦çš„æ˜¯ï¼Œæ‚¨ç°åœ¨æŒæ¡äº†æ‰€æœ‰å¿…è¦çš„å·¥å…·ï¼Œå¯ä»¥åœ¨ä»»ä½•è¯­éŸ³è¯†åˆ«æ•°æ®é›†æˆ–é¢†åŸŸä¸Šå¾®è°ƒ Whisper æ¨¡å‹ã€‚
é‚£ä¹ˆï¼Œæ‚¨è¿˜åœ¨ç­‰ä»€ä¹ˆå‘¢ï¼ä» [é€‰æ‹©æ•°æ®é›†](choosing_dataset) ç« èŠ‚ä¸­ä»‹ç»çš„æ•°æ®é›†é‡ŒæŒ‘ä¸€ä¸ªï¼Œæˆ–é€‰æ‹©æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œçœ‹çœ‹æ‚¨æ˜¯å¦å¯ä»¥è·å¾— SOTAï¼æ’è¡Œæ¦œåœ¨ç­‰ç€æ‚¨â€¦â€¦
