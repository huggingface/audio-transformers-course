# å¾®è°ƒ SpeechT5

ç°åœ¨æ‚¨å·²ç»ç†Ÿæ‚‰äº†è¯­éŸ³åˆæˆä»»åŠ¡å’Œ SpeechT5 æ¨¡å‹çš„å†…éƒ¨å·¥ä½œåŸç†ï¼Œè¯¥æ¨¡å‹æ˜¯åœ¨è‹±è¯­æ•°æ®ä¸Šé¢„è®­ç»ƒçš„ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å°†å…¶å¾®è°ƒåˆ°å¦ä¸€ç§è¯­è¨€ã€‚

## åŸºç¡€å‡†å¤‡

å¦‚æœæ‚¨æƒ³å¤ç°è¿™ä¸ªç¤ºä¾‹ï¼Œè¯·ç¡®ä¿æ‚¨æœ‰ä¸€ä¸ª GPUã€‚åœ¨ç¬”è®°æœ¬ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ï¼š

```bash
nvidia-smi
```

<Tip warning={true}>

åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¤§çº¦ 40 å°æ—¶çš„è®­ç»ƒæ•°æ®ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨ Google Colab å…è´¹ç‰ˆçš„ GPU å¤ç°ï¼Œéœ€è¦å°†è®­ç»ƒæ•°æ®é‡å‡å°‘åˆ°å¤§çº¦ 10-15 å°æ—¶ï¼Œå¹¶å‡å°‘è®­ç»ƒæ­¥éª¤çš„æ•°é‡ã€‚

</Tip>

æ‚¨è¿˜éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–ï¼š

```bash
pip install transformers datasets soundfile speechbrain accelerate
```

æœ€åï¼Œä¸è¦å¿˜è®°ç™»å½•æ‚¨çš„ Hugging Face è´¦æˆ·ï¼Œä»¥ä¾¿æ‚¨èƒ½å¤Ÿä¸Šä¼ å¹¶ä¸ç¤¾åŒºå…±äº«æ‚¨çš„æ¨¡å‹ï¼š

```py
from huggingface_hub import notebook_login

notebook_login()
```

## æ•°æ®é›†

åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) æ•°æ®é›†çš„è·å…°è¯­ï¼ˆ`nl`ï¼‰å­é›†ã€‚
[VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šè¯­è¨€è¯­éŸ³è¯­æ–™åº“ï¼ŒåŒ…å«äº† 2009-2020 å¹´æ¬§æ´²è®®ä¼šäº‹ä»¶çš„å½•éŸ³æ•°æ®ã€‚
å®ƒåŒ…å« 15 ç§æ¬§æ´²è¯­è¨€çš„å¸¦æ ‡ç­¾çš„éŸ³é¢‘-è½¬å†™æ•°æ®ã€‚è™½ç„¶æˆ‘ä»¬å°†ä½¿ç”¨è·å…°è¯­å­é›†ï¼Œä½†æ‚¨å¯ä»¥è‡ªç”±é€‰æ‹©å…¶ä»–å­é›†ã€‚

è¿™æ˜¯ä¸€ä¸ªè¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ•°æ®é›†ï¼Œæ‰€ä»¥ï¼Œå¦‚å‰æ‰€è¿°ï¼Œå®ƒä¸æ˜¯è®­ç»ƒ TTS æ¨¡å‹çš„æœ€ä½³é€‰æ‹©ã€‚ç„¶è€Œï¼Œå¯¹äºè¿™ä¸ªç»ƒä¹ æ¥è¯´ï¼Œå®ƒå·²ç»è¶³å¤Ÿå¥½äº†ã€‚

è®©æˆ‘ä»¬åŠ è½½æ•°æ®ï¼š

```python
from datasets import load_dataset, Audio

dataset = load_dataset("facebook/voxpopuli", "nl", split="train")
len(dataset)
```

**è¾“å‡ºï¼š**

```out
20968
```

20968 æ¡æ•°æ®åº”è¯¥è¶³ä»¥è¿›è¡Œå¾®è°ƒã€‚è¾“å…¥ SpeechT5 çš„éŸ³é¢‘æ•°æ®åº”å…·æœ‰ 16 kHz çš„é‡‡æ ·ç‡ï¼Œæ‰€ä»¥è¦ç¡®ä¿æˆ‘ä»¬çš„æ•°æ®é›†æ»¡è¶³è¿™ä¸€è¦æ±‚ï¼š

```python
dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
```

## æ•°æ®é¢„å¤„ç†

å¤„ç†å™¨åŒ…å«äº†åˆ†è¯å™¨å’Œç‰¹å¾æå–å™¨ï¼Œæˆ‘ä»¬éœ€è¦ç”¨å®ƒä»¬æ¥é¢„å¤„ç†è®­ç»ƒæ•°æ®ã€‚æ‰€ä»¥æˆ‘ä»¬å…ˆå®šä¹‰è¦ä½¿ç”¨çš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œå¹¶åŠ è½½å¯¹åº”çš„å¤„ç†å™¨ï¼š

```py
from transformers import SpeechT5Processor

checkpoint = "microsoft/speecht5_tts"
processor = SpeechT5Processor.from_pretrained(checkpoint)
```

### ä¸º SpeechT5 åˆ†è¯è¿›è¡Œæ–‡æœ¬æ¸…ç†

é¦–å…ˆï¼Œä¸ºäº†å¤„ç†æ–‡æœ¬ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†å™¨çš„åˆ†è¯å™¨éƒ¨åˆ†ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ¥è·å–å®ƒï¼š

```py
tokenizer = processor.tokenizer
```

è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š

```python
dataset[0]
```

**è¾“å‡ºï¼š**

```out
{'audio_id': '20100210-0900-PLENARY-3-nl_20100210-09:06:43_4',
 'language': 9,
 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/02ec6a19d5b97c03e1379250378454dbf3fa2972943504a91c7da5045aa26a89/train_part_0/20100210-0900-PLENARY-3-nl_20100210-09:06:43_4.wav',
  'array': array([ 4.27246094e-04,  1.31225586e-03,  1.03759766e-03, ...,
         -9.15527344e-05,  7.62939453e-04, -2.44140625e-04]),
  'sampling_rate': 16000},
 'raw_text': 'Dat kan naar mijn gevoel alleen met een brede meerderheid die wij samen zoeken.',
 'normalized_text': 'dat kan naar mijn gevoel alleen met een brede meerderheid die wij samen zoeken.',
 'gender': 'female',
 'speaker_id': '1122',
 'is_gold_transcript': True,
 'accent': 'None'}
```

æ‚¨å¯èƒ½ä¼šæ³¨æ„åˆ°æ•°æ®åŒ…å« `raw_text` å’Œ `normalized_text` ç‰¹å¾ã€‚åœ¨å†³å®šä½¿ç”¨å“ªä¸ªç‰¹å¾ä½œä¸ºæ–‡æœ¬è¾“å…¥æ—¶ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ SpeechT5 åˆ†è¯å™¨æ²¡æœ‰ä»»ä½•æ•°å­—çš„è¯å…ƒã€‚
åœ¨ `normalized_text` ä¸­ï¼Œæ•°å­—è¢«å†™æˆæ–‡æœ¬ã€‚å› æ­¤ï¼Œå®ƒæ›´åˆé€‚ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨ `normalized_text` ä½œä¸ºè¾“å…¥æ–‡æœ¬ã€‚

å› ä¸º SpeechT5 æ˜¯åœ¨è‹±è¯­ä¸Šè®­ç»ƒçš„ï¼Œå®ƒå¯èƒ½æ— æ³•è¯†åˆ«è·å…°è¯­æ•°æ®é›†ä¸­çš„æŸäº›å­—ç¬¦ã€‚å¦‚æœä¿æŒåŸæ ·ï¼Œè¿™äº›å­—ç¬¦å°†è¢«è½¬æ¢ä¸º `<unk>` è¯å…ƒã€‚
ç„¶è€Œï¼Œåœ¨è·å…°è¯­ä¸­ï¼ŒæŸäº›å­—ç¬¦å¦‚ `Ã ` ç”¨äºå¼ºè°ƒéŸ³èŠ‚ã€‚ä¸ºäº†ä¿ç•™æ–‡æœ¬çš„å«ä¹‰ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ­¤å­—ç¬¦æ›¿æ¢ä¸ºæ™®é€šçš„ `a`ã€‚

è¦è¯†åˆ«ä¸æ”¯æŒçš„è¯å…ƒï¼Œä½¿ç”¨ `SpeechT5Tokenizer` æå–æ•°æ®é›†ä¸­æ‰€æœ‰ç‹¬ç‰¹å­—ç¬¦ï¼Œè¯¥åˆ†è¯å™¨å°†å­—ç¬¦è§†ä¸ºè¯å…ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ç¼–å†™ `extract_all_chars` æ˜ å°„å‡½æ•°ï¼Œ
è¯¥å‡½æ•°å°†æ‰€æœ‰æ•°æ®æ ·ä¾‹çš„è½¬å†™è¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç„¶åè½¬æ¢ä¸ºå­—ç¬¦é›†ã€‚ç¡®ä¿åœ¨ `dataset.map()` ä¸­è®¾ç½® `batched=True` å’Œ `batch_size=-1`ï¼Œä»¥ä¾¿ä¸€æ¬¡æ€§è·å–æ‰€æœ‰è½¬å†™å¹¶è¾“å…¥æ˜ å°„å‡½æ•°ã€‚

```py
def extract_all_chars(batch):
    all_text = " ".join(batch["normalized_text"])
    vocab = list(set(all_text))
    return {"vocab": [vocab], "all_text": [all_text]}


vocabs = dataset.map(
    extract_all_chars,
    batched=True,
    batch_size=-1,
    keep_in_memory=True,
    remove_columns=dataset.column_names,
)

dataset_vocab = set(vocabs["vocab"][0])
tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}
```

ç°åœ¨æ‚¨æœ‰ä¸¤ç»„å­—ç¬¦ï¼šä¸€ä¸ªæ¥è‡ªæ•°æ®é›†ï¼Œå¦ä¸€ä¸ªæ¥è‡ªåˆ†è¯å™¨ã€‚è¦è¯†åˆ«æ•°æ®é›†ä¸­ä»»ä½•ä¸æ”¯æŒçš„å­—ç¬¦ï¼Œæ‚¨å¯ä»¥å–è¿™ä¸¤ç»„çš„å·®é›†ï¼Œç»“æœå°†åŒ…å«åœ¨æ•°æ®é›†ä¸­è€Œä¸åœ¨åˆ†è¯å™¨ä¸­çš„å­—ç¬¦ã€‚

```py
dataset_vocab - tokenizer_vocab
```

**è¾“å‡ºï¼š**

```out
{' ', 'Ã ', 'Ã§', 'Ã¨', 'Ã«', 'Ã­', 'Ã¯', 'Ã¶', 'Ã¼'}
```

ä¸ºäº†å¤„ç†ä¸Šä¸€æ­¥éª¤ä¸­è¯†åˆ«çš„ä¸æ”¯æŒå­—ç¬¦ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå°†è¿™äº›å­—ç¬¦æ˜ å°„åˆ°æœ‰æ•ˆè¯å…ƒçš„å‡½æ•°ã€‚æ³¨æ„ï¼Œåˆ†è¯å™¨ä¸­çš„ç©ºæ ¼å·²ç»è¢«æ›¿æ¢ä¸º `â–`ï¼Œå› æ­¤ä¸éœ€è¦å•ç‹¬å¤„ç†ã€‚

```py
replacements = [
    ("Ã ", "a"),
    ("Ã§", "c"),
    ("Ã¨", "e"),
    ("Ã«", "e"),
    ("Ã­", "i"),
    ("Ã¯", "i"),
    ("Ã¶", "o"),
    ("Ã¼", "u"),
]


def cleanup_text(inputs):
    for src, dst in replacements:
        inputs["normalized_text"] = inputs["normalized_text"].replace(src, dst)
    return inputs


dataset = dataset.map(cleanup_text)
```

ç°åœ¨æˆ‘ä»¬å¤„ç†å¥½äº†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œæ˜¯æ—¶å€™å°†æ³¨æ„åŠ›è½¬ç§»åˆ°éŸ³é¢‘æ•°æ®ä¸Šäº†ã€‚

### è¯´è¯äºº

VoxPopuli æ•°æ®é›†åŒ…å«å¤šä¸ªè¯´è¯äººçš„è¯­éŸ³ï¼Œä½†åˆ°åº•æœ‰å¤šå°‘å‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥è®¡ç®—ä¸€ä¸‹æ•°æ®é›†ä¸­è¯´è¯äººçš„æ•°é‡ä»¥åŠæ¯ä¸ªè¯´è¯äººè´¡çŒ®çš„æ•°æ®é‡ã€‚
æ•°æ®é›†æ€»å…±æœ‰ 20,968 æ¡æ•°æ®ï¼Œè¿™äº›ä¿¡æ¯å°†å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°äº†è§£æ•°æ®ä¸­çš„è¯´è¯äººå’Œæ•°æ®æ ·ä¾‹çš„åˆ†å¸ƒã€‚

```py
from collections import defaultdict

speaker_counts = defaultdict(int)

for speaker_id in dataset["speaker_id"]:
    speaker_counts[speaker_id] += 1
```

é€šè¿‡ç»˜åˆ¶ç›´æ–¹å›¾ï¼Œæ‚¨å¯ä»¥äº†è§£æ¯ä¸ªè¯´è¯äººçš„æ•°æ®é‡ã€‚

```py
import matplotlib.pyplot as plt

plt.figure()
plt.hist(speaker_counts.values(), bins=20)
plt.ylabel("Speakers")
plt.xlabel("Examples")
plt.show()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_speakers_histogram.png" alt="Speakers histogram"/>
</div>

ç›´æ–¹å›¾æ˜¾ç¤ºï¼Œæ•°æ®é›†ä¸­å¤§çº¦ä¸‰åˆ†ä¹‹ä¸€çš„è¯´è¯äººçš„æ•°æ®å°‘äº 100 æ¡ï¼Œè€Œå¤§çº¦åä¸ªè¯´è¯äººçš„æ•°æ®è¶…è¿‡ 500 æ¡ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡å¹¶å¹³è¡¡æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®é™åˆ¶åœ¨æœ‰ 100 åˆ° 400 æ¡æ•°æ®çš„è¯´è¯äººä¹‹é—´ã€‚

```py
def select_speaker(speaker_id):
    return 100 <= speaker_counts[speaker_id] <= 400


dataset = dataset.filter(select_speaker, input_columns=["speaker_id"])
```

è®©æˆ‘ä»¬æ£€æŸ¥è¿˜å‰©å¤šå°‘ä¸ªè¯´è¯äººï¼š

```py
len(set(dataset["speaker_id"]))
```

**è¾“å‡ºï¼š**

```out
42
```

è®©æˆ‘ä»¬çœ‹çœ‹è¿˜å‰©å¤šå°‘æ¡æ•°æ®ï¼š

```py
len(dataset)
```

**è¾“å‡ºï¼š**

```out
9973
```

æ‚¨ç•™ä¸‹äº†ä¸åˆ° 10,000 æ¡æ•°æ®ï¼Œæ¥è‡ªå¤§çº¦ 40 ä¸ªç‹¬ç‰¹çš„è¯´è¯äººï¼Œè¿™åº”è¯¥è¶³å¤Ÿç”¨äº†ã€‚

è¯·æ³¨æ„ï¼Œå¦‚æœæŸäº›æ•°æ®å¾ˆé•¿ï¼Œä¸€äº›çœ‹ä¼¼æ•°æ®æ ·ä¾‹é‡è¾ƒå°‘çš„è¯´è¯äººå¯èƒ½æœ‰æ¯”é¢„æƒ³çš„æ›´å¤šçš„éŸ³é¢‘æ•°æ®ã€‚ç„¶è€Œï¼Œç¡®å®šæ¯ä¸ªè¯´è¯äººçš„æ€»éŸ³é¢‘é‡éœ€è¦æ‰«ææ•´ä¸ªæ•°æ®é›†ï¼Œ
è¿™æ˜¯ä¸€ä¸ªè€—æ—¶çš„è¿‡ç¨‹ï¼Œæ¶‰åŠåŠ è½½å’Œè§£ç æ¯ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œé€‰æ‹©è·³è¿‡è¿™ä¸€æ­¥ã€‚

### è¯´è¯äººåµŒå…¥

ä¸ºäº†ä½¿ TTS æ¨¡å‹èƒ½å¤ŸåŒºåˆ†å¤šä¸ªè¯´è¯äººï¼Œæ‚¨éœ€è¦ä¸ºæ¯æ¡æ•°æ®åˆ›å»ºä¸€ä¸ªè¯´è¯äººåµŒå…¥ã€‚è¯´è¯äººåµŒå…¥æ˜¯æ¨¡å‹çš„ä¸€ä¸ªé¢å¤–è¾“å…¥ï¼Œç”¨äºæè¿°ç‰¹å®šè¯´è¯äººçš„å£°éŸ³ç‰¹å¾ã€‚
è¦ç”Ÿæˆè¿™äº›è¯´è¯äººåµŒå…¥ï¼Œå¯ä»¥ä½¿ç”¨æ¥è‡ª SpeechBrain çš„é¢„è®­ç»ƒæ¨¡å‹ [spkrec-xvect-voxceleb](https://huggingface.co/speechbrain/spkrec-xvect-voxceleb)ã€‚

åˆ›å»ºä¸€ä¸ª `create_speaker_embedding()` å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—éŸ³é¢‘æ³¢å½¢ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºåŒ…å«ç›¸åº”è¯´è¯äººåµŒå…¥çš„ 512 ç»´å‘é‡ã€‚

```py
import os
import torch
from speechbrain.inference import EncoderClassifier

spk_model_name = "speechbrain/spkrec-xvect-voxceleb"

device = "cuda" if torch.cuda.is_available() else "cpu"
speaker_model = EncoderClassifier.from_hparams(
    source=spk_model_name,
    run_opts={"device": device},
    savedir=os.path.join("/tmp", spk_model_name),
)


def create_speaker_embedding(waveform):
    with torch.no_grad():
        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))
        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)
        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()
    return speaker_embeddings
```

æ³¨æ„ï¼Œ`speechbrain/spkrec-xvect-voxceleb` æ¨¡å‹æ˜¯åœ¨ VoxCeleb æ•°æ®é›†çš„è‹±è¯­è¯­éŸ³ä¸Šè®­ç»ƒçš„ï¼Œè€Œè¿™ä¸ªç¤ºä¾‹è®­ç»ƒçš„æ˜¯è·å…°è¯­ã€‚
è™½ç„¶æˆ‘ä»¬ç›¸ä¿¡è¿™ä¸ªæ¨¡å‹ä»ç„¶å¯ä»¥ä¸ºæˆ‘ä»¬çš„è·å…°è¯­æ•°æ®é›†ç”Ÿæˆåˆç†çš„è¯´è¯äººåµŒå…¥ï¼Œä½†è¿™ä¸ªå‡è®¾å¯èƒ½ä¸æ€»æ˜¯æˆç«‹ã€‚

ä¸ºäº†è·å¾—æœ€ä½³ç»“æœï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆåœ¨ç›®æ ‡è¯­éŸ³ä¸Šè®­ç»ƒ X-Vector æ¨¡å‹ã€‚è¿™å°†ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è·å…°è¯­ä¸­å­˜åœ¨çš„ç‹¬ç‰¹å£°éŸ³ç‰¹å¾ã€‚å¦‚æœæ‚¨æƒ³è®­ç»ƒè‡ªå·±çš„ X-å‘é‡æ¨¡å‹ï¼Œ
å¯ä»¥å‚è€ƒ [æ­¤è„šæœ¬](https://huggingface.co/mechanicalsea/speecht5-vc/blob/main/manifest/utils/prep_cmu_arctic_spkemb.py)ã€‚

### å¤„ç†æ•°æ®é›†

æœ€åï¼Œè®©æˆ‘ä»¬å°†æ•°æ®å¤„ç†æˆæ¨¡å‹èƒ½å¤Ÿè¯»å…¥çš„æ ¼å¼ã€‚åˆ›å»ºä¸€ä¸ª `prepare_dataset` å‡½æ•°ï¼Œè¾“å…¥å•ä¸ªç¤ºä¾‹å¹¶ä½¿ç”¨ `SpeechT5Processor` å¯¹è±¡æ¥å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œå¹¶å°†ç›®æ ‡éŸ³é¢‘åŠ è½½æˆå¯¹æ•°æ¢…å°”è°±ã€‚å®ƒè¿˜åº”è¯¥é¢å¤–è¾“å…¥è¯´è¯äººåµŒå…¥ã€‚

```py
def prepare_dataset(example):
    audio = example["audio"]

    example = processor(
        text=example["normalized_text"],
        audio_target=audio["array"],
        sampling_rate=audio["sampling_rate"],
        return_attention_mask=False,
    )

    # å»æ‰æ‰¹é‡å¤„ç†çš„ç»´åº¦
    example["labels"] = example["labels"][0]

    # ç”¨ SpeechBrain è·å– X-Vector
    example["speaker_embeddings"] = create_speaker_embedding(audio["array"])

    return example
```

æŸ¥çœ‹å•ä¸ªç¤ºä¾‹æ¥éªŒè¯å¤„ç†æ˜¯å¦æ­£ç¡®ï¼š

```py
processed_example = prepare_dataset(dataset[0])
list(processed_example.keys())
```

**è¾“å‡ºï¼š**

```out
['input_ids', 'labels', 'stop_labels', 'speaker_embeddings']
```

è¯´è¯äººåµŒå…¥åº”è¯¥æ˜¯ä¸€ä¸ª 512 ç»´å‘é‡ï¼š

```py
processed_example["speaker_embeddings"].shape
```

**è¾“å‡ºï¼š**

```out
(512,)
```

æ ‡ç­¾åº”è¯¥æ˜¯ä¸€ä¸ªæœ‰ 80 ä¸ª mel é¢‘æ®µçš„å¯¹æ•°æ¢…å°”è°±ã€‚

```py
import matplotlib.pyplot as plt

plt.figure()
plt.imshow(processed_example["labels"].T)
plt.show()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_logmelspectrogram_1.png" alt="Log-mel spectrogram with 80 mel bins"/>
</div>

æ³¨ï¼šå¦‚æœæ‚¨çœ‹ä¸æ˜ç™½è¿™ä¸ªé¢‘è°±å›¾ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ‚¨ä¹ æƒ¯å°†ä½é¢‘æ”¾åœ¨åº•éƒ¨ï¼Œé«˜é¢‘æ”¾åœ¨é¡¶éƒ¨ã€‚ç„¶è€Œï¼Œåœ¨ä½¿ç”¨ matplotlib åº“å°†é¢‘è°±å›¾ä½œä¸ºå›¾åƒç»˜åˆ¶æ—¶ï¼Œy è½´æ˜¯åè¿‡æ¥çš„ï¼Œé¢‘è°±å›¾çœ‹èµ·æ¥æ˜¯å€’ç½®çš„ã€‚

ç°åœ¨æˆ‘ä»¬éœ€è¦å°†å¤„ç†å‡½æ•°åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†ã€‚è¿™å°†èŠ±è´¹ 5 åˆ° 10 åˆ†é’Ÿçš„æ—¶é—´ã€‚

```py
dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)
```

æ‚¨ä¼šçœ‹åˆ°ä¸€ä¸ªè­¦å‘Šè¯´æ•°æ®é›†ä¸­çš„æŸäº›æ•°æ®é•¿äºæ¨¡å‹èƒ½å¤Ÿå¤„ç†çš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼ˆ600 è¯å…ƒï¼‰ï¼Œå¾—ä»æ•°æ®é›†ä¸­åˆ é™¤è¿™äº›æ•°æ®ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ›´è¿›ä¸€æ­¥ï¼Œä¸ºäº†å…è®¸æ›´å¤§çš„æ‰¹é‡å¤§å°ï¼Œåˆ é™¤ä»»ä½•è¶…è¿‡ 200 è¯å…ƒçš„å†…å®¹ã€‚

```py
def is_not_too_long(input_ids):
    input_length = len(input_ids)
    return input_length < 200


dataset = dataset.filter(is_not_too_long, input_columns=["input_ids"])
len(dataset)
```

**è¾“å‡ºï¼š**

```out
8259
```

æ¥ä¸‹æ¥ï¼ŒæŠŠæ•°æ®é›†åˆ†æˆåŸºæœ¬çš„è®­ç»ƒ/æµ‹è¯•å­é›†ï¼š

```py
dataset = dataset.train_test_split(test_size=0.1)
```

### æ•°æ®æ•´ç†å™¨

ä¸ºäº†å°†å¤šæ¡æ•°æ®ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡ï¼Œæ‚¨éœ€è¦å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰æ•°æ®æ•´ç†å™¨ã€‚è¿™ä¸ªæ•´ç†å™¨å°†ä½¿ç”¨å¡«å……è¯å…ƒå¡«å……è¾ƒçŸ­çš„åºåˆ—ï¼Œç¡®ä¿æ‰€æœ‰ç¤ºä¾‹éƒ½å…·æœ‰ç›¸åŒçš„é•¿åº¦ã€‚
å¯¹äºé¢‘è°±å›¾æ ‡ç­¾ï¼Œå¡«å……éƒ¨åˆ†å°†è¢«ç‰¹æ®Šå€¼ `-100` æ›¿æ¢ã€‚è¿™ä¸ªç‰¹æ®Šå€¼æŒ‡ç¤ºæ¨¡å‹åœ¨è®¡ç®—é¢‘è°±å›¾çš„æŸå¤±å‡½æ•°æ—¶å¿½ç•¥é‚£éƒ¨åˆ†é¢‘è°±å›¾ã€‚

```py
from dataclasses import dataclass
from typing import Any, Dict, List, Union


@dataclass
class TTSDataCollatorWithPadding:
    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        input_ids = [{"input_ids": feature["input_ids"]} for feature in features]
        label_features = [{"input_values": feature["labels"]} for feature in features]
        speaker_features = [feature["speaker_embeddings"] for feature in features]

        # æŠŠè¾“å…¥æ•°æ®å’Œç”Ÿæˆç›®æ ‡æ•´åˆè¿›ä¸€ä¸ªæ‰¹æ¬¡
        batch = processor.pad(
            input_ids=input_ids, labels=label_features, return_tensors="pt"
        )

        # æŠŠå¡«å……è¯å…ƒæ¢æˆ -100 æ¥æ­£ç¡®åœ°å¿½ç•¥è¿™ä¸€éƒ¨åˆ†çš„æŸå¤±å‡½æ•°
        batch["labels"] = batch["labels"].masked_fill(
            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100
        )

        # åœ¨å¾®è°ƒæ—¶ç”¨ä¸ä¸Šï¼Œåˆ äº†
        del batch["decoder_attention_mask"]

        # æŠŠç›®æ ‡é•¿åº¦ä¸‹è°ƒåˆ° reduction factor çš„æ•´æ•°å€
        if model.config.reduction_factor > 1:
            target_lengths = torch.tensor(
                [len(feature["input_values"]) for feature in label_features]
            )
            target_lengths = target_lengths.new(
                [
                    length - length % model.config.reduction_factor
                    for length in target_lengths
                ]
            )
            max_length = max(target_lengths)
            batch["labels"] = batch["labels"][:, :max_length]

        # åŠ ä¸Šè¯´è¯äººåµŒå…¥
        batch["speaker_embeddings"] = torch.tensor(speaker_features)

        return batch
```

åœ¨ SpeechT5 ä¸­ï¼Œæ¨¡å‹çš„è§£ç å™¨éƒ¨åˆ†çš„è¾“å…¥å‡å°‘äº† 2 å€ï¼ˆreduction factorï¼‰ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒæŠ›å¼ƒäº†ç›®æ ‡åºåˆ—ä¸­æ¯ä¸¤æ­¥ä¸­çš„ä¸€æ­¥ã€‚ç„¶åï¼Œè§£ç å™¨é¢„æµ‹ä¸€ä¸ªä¸¤å€é•¿åº¦çš„åºåˆ—ã€‚
ç”±äºåŸæ¥çš„ç›®æ ‡åºåˆ—é•¿åº¦å¯èƒ½æ˜¯å¥‡æ•°ï¼Œæ•°æ®æ•´ç†å™¨ä¼šç¡®ä¿å°†æ‰¹æ¬¡çš„æœ€å¤§é•¿åº¦è°ƒæ•´ä¸º 2 çš„å€æ•°ã€‚

```py 
data_collator = TTSDataCollatorWithPadding(processor=processor)
```

## è®­ç»ƒæ¨¡å‹

ä»ä¸å¤„ç†å™¨ç›¸åŒçš„æ£€æŸ¥ç‚¹åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼š

```py
from transformers import SpeechT5ForTextToSpeech

model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)
```

`use_cache=True` é€‰é¡¹ä¸æ¢¯åº¦æ£€æŸ¥ç‚¹ä¸å…¼å®¹ã€‚æˆ‘ä»¬åœ¨è®­ç»ƒæ—¶ç¦ç”¨è¿™ä¸ªé€‰é¡¹ï¼Œå¹¶åœ¨ç”Ÿæˆæ—¶é‡æ–°å¯ç”¨ç¼“å­˜ä»¥åŠ å¿«æ¨ç†ï¼š

```py 
from functools import partial

# åœ¨è®­ç»ƒæ—¶ç¦ç”¨ç¼“å­˜
model.config.use_cache = False

# è®¾ç½®è¯­è¨€å’Œä»»åŠ¡å‡†å¤‡æ¨ç†ï¼Œå¹¶é‡æ–°å¯ç”¨ç¼“å­˜
model.generate = partial(model.generate, use_cache=True)
``` 

å®šä¹‰è®­ç»ƒå‚æ•°ã€‚è¿™é‡Œæˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸è®¡ç®—ä»»ä½•è¯„ä¼°æŒ‡æ ‡ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ç« ç¨åè®¨è®ºè¯„ä¼°ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å…ˆåªå…³æ³¨æŸå¤±å‡½æ•°ï¼š

```python
from transformers import Seq2SeqTrainingArguments

training_args = Seq2SeqTrainingArguments(
    output_dir="speecht5_finetuned_voxpopuli_nl",  # æ”¹æˆæ‚¨é€‰æ‹©çš„ä»“åº“å
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,
    learning_rate=1e-5,
    warmup_steps=500,
    max_steps=4000,
    gradient_checkpointing=True,
    fp16=True,
    evaluation_strategy="steps",
    per_device_eval_batch_size=2,
    save_steps=1000,
    eval_steps=1000,
    logging_steps=25,
    report_to=["tensorboard"],
    load_best_model_at_end=True,
    greater_is_better=False,
    label_names=["labels"],
    push_to_hub=True,
)
```

å®ä¾‹åŒ– `Trainer` å¯¹è±¡å¹¶å°†æ¨¡å‹ã€æ•°æ®é›†å’Œæ•°æ®æ•´ç†å™¨ä¼ é€’ç»™å®ƒã€‚

```py
from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    args=training_args,
    model=model,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    data_collator=data_collator,
    tokenizer=processor,
)
```

æœ‰äº†è¿™ä¸ªï¼Œæˆ‘ä»¬å°±å‡†å¤‡å¼€å§‹è®­ç»ƒäº†ï¼è®­ç»ƒå°†èŠ±è´¹å‡ ä¸ªå°æ—¶ã€‚ç”±äº GPU ä¸åŒï¼Œå½“æ‚¨å¼€å§‹è®­ç»ƒæ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ° CUDA æŠ¥â€œout-of-memoryâ€ï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰çš„é”™è¯¯ã€‚è¿™æ—¶ï¼Œæ‚¨å¯ä»¥å°è¯•å°† `per_device_train_batch_size` ä¸¤å€ä¸¤å€åœ°å‡å°‘ï¼Œå¹¶å°† `gradient_accumulation_steps` å¢åŠ åˆ°ä¸¤å€ä»¥è¡¥å¿ã€‚

```py
trainer.train()
```

å°†æœ€ç»ˆçš„æ¨¡å‹ä¸Šä¼ åˆ° ğŸ¤— Hubï¼š

```py
trainer.push_to_hub()
```

## æ¨ç†

ä¸€æ—¦æ‚¨å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œæ‚¨å°±å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†ï¼ä» ğŸ¤— Hub åŠ è½½æ¨¡å‹ï¼ˆè®°å¾—åœ¨ä»¥ä¸‹ä»£ç ç‰‡æ®µä¸­ä½¿ç”¨æ‚¨çš„è´¦å·åï¼‰ï¼š

```py
model = SpeechT5ForTextToSpeech.from_pretrained(
    "æ‚¨çš„è´¦å·/speecht5_finetuned_voxpopuli_nl"
)
```

é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹ï¼Œè¿™é‡Œæˆ‘ä»¬å°†ä»æµ‹è¯•æ•°æ®é›†ä¸­å–ä¸€ä¸ªã€‚è·å–è¯´è¯äººåµŒå…¥ã€‚

```py 
example = dataset["test"][304]
speaker_embeddings = torch.tensor(example["speaker_embeddings"]).unsqueeze(0)
```

å®šä¹‰ä¸€äº›è¾“å…¥æ–‡æœ¬å¹¶å¯¹å®ƒè¿›è¡Œåˆ†è¯ã€‚

```py 
text = "hallo allemaal, ik praat nederlands. groetjes aan iedereen!"
```

é¢„å¤„ç†è¾“å…¥æ–‡æœ¬ï¼š

```py
inputs = processor(text=text, return_tensors="pt")
```

å®ä¾‹åŒ–ä¸€ä¸ªå£°ç å™¨å¹¶ç”Ÿæˆè¯­éŸ³ï¼š

```py
from transformers import SpeechT5HifiGan

vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
speech = model.generate_speech(inputs["input_ids"], speaker_embeddings, vocoder=vocoder)
```

å‡†å¤‡å¥½å¬ç»“æœäº†å—ï¼Ÿ

```py
from IPython.display import Audio

Audio(speech.numpy(), rate=16000)
```

ç”¨è¿™ä¸ªæ¨¡å‹åœ¨æ–°è¯­è¨€ä¸Šè·å¾—çš„æ»¡æ„ç»“æœå¯èƒ½å¾ˆæœ‰æŒ‘æˆ˜æ€§ã€‚è¯´è¯äººåµŒå…¥çš„è´¨é‡å¯èƒ½æ˜¯ä¸€ä¸ªé‡è¦å› ç´ ã€‚ç”±äº SpeechT5 æ˜¯ä½¿ç”¨è‹±è¯­ X-Vector é¢„è®­ç»ƒçš„ï¼Œå®ƒåœ¨ä½¿ç”¨è‹±è¯­è¯´è¯äººåµŒå…¥æ—¶è¡¨ç°æœ€ä½³ã€‚å¦‚æœåˆæˆçš„è¯­éŸ³å¬èµ·æ¥æ•ˆæœä¸å¥½ï¼Œå°è¯•ä½¿ç”¨ä¸åŒçš„è¯´è¯äººåµŒå…¥ã€‚

å¢åŠ è®­ç»ƒæ—¶é•¿ä¹Ÿå¯èƒ½æé«˜ç»“æœçš„è´¨é‡ã€‚ä½†å³ä¾¿ä¸ç»§ç»­è®­ç»ƒï¼Œè¯­éŸ³ä¹Ÿæ˜¾ç„¶æ˜¯è·å…°è¯­è€Œä¸æ˜¯è‹±è¯­ï¼Œå¹¶ä¸”å®ƒç¡®å®å­¦åˆ°äº†è¯´è¯äººçš„å£°éŸ³ç‰¹å¾ï¼ˆä¸ç¤ºä¾‹ä¸­çš„åŸå§‹éŸ³é¢‘ç›¸æ¯”è¾ƒï¼‰ã€‚å¦ä¸€ä¸ªå¯ä»¥è¯•éªŒçš„æ˜¯æ¨¡å‹çš„é…ç½®ã€‚ä¾‹å¦‚ï¼Œå°è¯•ä½¿ç”¨ `config.reduction_factor = 1` æ¥çœ‹æ˜¯å¦èƒ½æ”¹å–„ç»“æœã€‚

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•è¯„ä¼°è¯­éŸ³åˆæˆæ¨¡å‹ã€‚
