# åŠ è½½éŸ³é¢‘æ•°æ®é›†

æœ¬èŠ‚ä¸­æˆ‘ä»¬å°†ä¼šä½¿ç”¨ğŸ¤— Datasetsæ¥è·å–éŸ³é¢‘æ•°æ®é›†ã€‚ğŸ¤— Datasetsæ˜¯ä¸€ä¸ªä¸‹è½½å’Œå‡†å¤‡æ•°æ®é›†çš„å¼€æºå·¥å…·ï¼ŒåŒ…å«äº†éŸ³é¢‘åœ¨å†…çš„å„ç§æ¨¡æ€æ•°æ®ã€‚è¯¥å·¥å…·é›†ä¸ºHugging Face Hubä¸Šå…¬å¼€çš„æœºå™¨å­¦ä¹ æ•°æ®é›†æä¾›äº†æ˜“ç”¨çš„æ¥å£ã€‚æ­¤å¤–ï¼ŒğŸ¤— Datasetsè¿˜æä¾›äº†ä¸“é—¨ä¸ºéŸ³é¢‘æ•°æ®é›†è€Œè®¾çš„å¤šç§ç‰¹æ€§ï¼Œå¸®åŠ©ç ”ç©¶è€…å’Œæœºå™¨å­¦ä¹ å®è·µè€…æ›´è½»æ¾åœ°ä½¿ç”¨è¿™äº›æ•°æ®é›†ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬è¦ç¡®è®¤å·²ç»å®‰è£…äº†ğŸ¤— Datasetsåº“ï¼š

```bash
pip install datasets[audio]
```

ğŸ¤— Datasetsçš„å…¶ä¸­ä¸€ä¸ªé‡ç£…åŠŸèƒ½æ˜¯å¯ä»¥ä½¿ç”¨`load_dataset()`å‡½æ•°è¾¾åˆ°ä»…ç”¨ä¸€è¡Œä»£ç ä¸‹è½½å’Œå‡†å¤‡æ•°æ®é›†ã€‚

è¿™é‡Œæˆ‘ä»¬æ¥åŠ è½½å’Œæ¢ç´¢[MINDS-14](https://huggingface.co/datasets/PolyAI/minds14)è¿™ä¸€éŸ³é¢‘æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†çš„å†…å®¹æ˜¯äººä»¬å‘æŸä¸ªç½‘é“¶ç³»ç»Ÿæé—®çš„å½•éŸ³ï¼ŒåŒ…å«äº†å¤šç§è¯­è¨€å’Œæ–¹è¨€ã€‚

ä¸ºäº†åŠ è½½MINDS-14æ•°æ®é›†ï¼Œæˆ‘ä»¬éœ€è¦å¤åˆ¶è¯¥æ•°æ®é›†åœ¨Hugging Face Hubä¸Šçš„identifierï¼ˆ`PolyAI/minds14`ï¼‰ï¼Œå¹¶å‘`load_dataset()`å‡½æ•°ä¼ å…¥è¯¥å‚æ•°ã€‚è¿™é‡Œæˆ‘ä»¬åªé€‰å–è¯¥æ•°æ®é›†çš„æ¾³å¤§åˆ©äºšå­é›†ï¼ˆ`en-AU`ï¼‰çš„è®­ç»ƒåˆ†é›†ï¼š

```py
from datasets import load_dataset

minds = load_dataset("PolyAI/minds14", name="en-AU", split="train")
minds
```

**è¾“å‡ºï¼š**
```out
Dataset(
    {
        features: [
            "path",
            "audio",
            "transcription",
            "english_transcription",
            "intent_class",
            "lang_id",
        ],
        num_rows: 654,
    }
)
```

è¯¥æ•°æ®é›†åŒ…å«äº†654ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œæ¯ä¸ªéƒ½æœ‰å¯¹åº”çš„è½¬å½•æ–‡å­—å’Œå…¶è‹±è¯­ç¿»è¯‘ï¼Œä»¥åŠä¸€ä¸ªä»£è¡¨è¯¢é—®äººç›®çš„çš„æ ‡ç­¾ã€‚"audio"åˆ—åˆ™åŒ…å«äº†åŸå§‹çš„éŸ³é¢‘æ•°æ®ã€‚æˆ‘ä»¬æ¥ä»”ç»†çœ‹çœ‹å…¶ä¸­çš„ä¸€ä¸ªæ ·æœ¬ï¼š

```py
example = minds[0]
example
```

**è¾“å‡º**
```out
{
    "path": "/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-AU~PAY_BILL/response_4.wav",
    "audio": {
        "path": "/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-AU~PAY_BILL/response_4.wav",
        "array": array(
            [0.0, 0.00024414, -0.00024414, ..., -0.00024414, 0.00024414, 0.0012207],
            dtype=float32,
        ),
        "sampling_rate": 8000,
    },
    "transcription": "I would like to pay my electricity bill using my card can you please assist",
    "english_transcription": "I would like to pay my electricity bill using my card can you please assist",
    "intent_class": 13,
    "lang_id": 2,
}
```

ä½ å¯èƒ½æ³¨æ„åˆ°äº†"audio"åˆ—åŒ…å«äº†å¥½å‡ ä¸ªç‰¹å¾ï¼Œå®ƒä»¬åˆ†åˆ«æ˜¯ï¼š
* `path`ï¼šéŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ï¼ˆè¿™é‡Œä¸º`*.wav`ï¼‰ã€‚
* `array`ï¼šè§£ç åçš„éŸ³é¢‘æ–‡ä»¶ï¼Œä»¥1ç»´NumPyæ•°ç»„è¡¨ç¤ºã€‚
* `sampling_rate`ï¼šéŸ³é¢‘æ–‡ä»¶çš„é‡‡æ ·ç‡ï¼ˆè¯¥æ ·æœ¬ä¸º8000èµ«å…¹ï¼‰ã€‚

`intent_class`åˆ™æ˜¯åˆ†ç±»çš„å…·ä½“ç±»åˆ«ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`int2str()`æ–¹æ³•å°†è¯¥æ•°å­—è½¬æ¢ä¸ºæœ‰æ„ä¹‰çš„å­—ç¬¦ä¸²ï¼š

```py
id2label = minds.features["intent_class"].int2str
id2label(example["intent_class"])
```

**è¾“å‡ºï¼š**
```out
"pay_bill"
```

åœ¨è¯¥æ ·æœ¬çš„è½¬å½•æ–‡å­—ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¯¥éŸ³é¢‘çš„å†…å®¹ç¡®å®æ˜¯æŸäººåœ¨æä¸€ä¸ªå…³äºè´¦å•çš„é—®é¢˜ã€‚

å¦‚æœä½ åªæ˜¯æƒ³ç”¨è¯¥å­é›†è®­ç»ƒä¸€ä¸ªéŸ³é¢‘åˆ†ç±»å™¨ï¼Œä½ å¯èƒ½ä¸éœ€è¦ä½¿ç”¨æ‰€æœ‰çš„ç‰¹å¾ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œ`lang_id`æ ‡ç­¾åœ¨è¯¥å­é›†ä¸­å…¨éƒ¨ä¸ºåŒæ ·çš„å€¼ï¼›`english_transcription`æ ‡ç­¾å’Œ`transcription`å‡ ä¹å®Œå…¨å«æœ‰ç›¸åŒçš„å†…å®¹ï¼Œå› æ­¤æˆ‘ä»¬ä¹Ÿå¯ä»¥èˆå¼ƒè¯¥æ ‡ç­¾ã€‚

ä½ å¯ä»¥ä½¿ç”¨ğŸ¤— Datasetsçš„`remove_columns()`æ–¹æ³•è½»æ¾åœ°ç§»é™¤æ‰€æœ‰ä¸ç›¸å…³çš„æ ‡ç­¾ï¼š

```py
columns_to_remove = ["lang_id", "english_transcription"]
minds = minds.remove_columns(columns_to_remove)
minds
```

**è¾“å‡ºï¼š**
```out
Dataset({features: ["path", "audio", "transcription", "intent_class"], num_rows: 654})
```

ç°åœ¨æˆ‘ä»¬å·²ç»åŠ è½½å¹¶æ£€éªŒäº†æ•°æ®é›†çš„åŸå§‹å†…å®¹ï¼Œè®©æˆ‘ä»¬æ¥å¬å‡ ä¸ªä¾‹å­å§ï¼æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`Gradio`ä¸­çš„`Blocks`åŠŸèƒ½å’Œ`Audio`åŠŸèƒ½ä»æ•°æ®é›†ä¸­è§£ç å‡ ä¸ªæ ·æœ¬ï¼š

```py
import gradio as gr


def generate_audio():
    example = minds.shuffle()[0]
    audio = example["audio"]
    return (
        audio["sampling_rate"],
        audio["array"],
    ), id2label(example["intent_class"])


with gr.Blocks() as demo:
    with gr.Column():
        for _ in range(4):
            audio, label = generate_audio()
            output = gr.Audio(audio, label=label)

demo.launch(debug=True)
```

ä½ ä¹Ÿå¯ä»¥å¯è§†åŒ–ä½ æƒ³è¦çš„æ ·æœ¬ã€‚è¿™é‡Œæˆ‘ä»¬è¯•ç€ç»˜åˆ¶ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ³¢å½¢å›¾ï¼š

```py   
import librosa
import matplotlib.pyplot as plt
import librosa.display

array = example["audio"]["array"]
sampling_rate = example["audio"]["sampling_rate"]

plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/waveform_unit1.png" alt="Waveform plot">
</div>

åŠ¨æ‰‹è¯•è¯•å§ï¼è¯•ç€ä¸‹è½½MINDS-14æ•°æ®é›†ä¸­å…¶ä»–è¯­è¨€æˆ–æ–¹è¨€çš„å­é›†ï¼Œè†å¬å¹¶å¯è§†åŒ–å…¶ä¸­çš„ä¸€äº›æ ·æœ¬ï¼Œæ„Ÿå—æ•´ä¸ªæ•°æ®é›†çš„å¤šæ ·æ€§ã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/datasets/PolyAI/minds14)æ‰¾åˆ°è¯­è¨€å’Œæ–¹è¨€çš„å…¨éƒ¨åˆ—è¡¨ï¼ˆä»…è‹±æ–‡ï¼‰ã€‚