# 襤lem hatt覺yla otomatik konuma tan覺ma

Otomatik Konuma Tan覺ma (ASR), konuma sesi kayd覺n覺n metne d繹n羹t羹r羹lmesini i癟eren bir g繹revdir.
Bu g繹revin, videolar i癟in altyaz覺 oluturmaktan sesli komutlar覺 etkinletirmeye kadar 癟ok say覺da pratik uygulamas覺 vard覺r.
Siri ve Alexa gibi sanal asistanlar i癟in.

Bu b繹l羹mde, bir kiinin ses kayd覺n覺 metne d繹n羹t羹rmek i癟in "otomatik konuma tan覺ma" hatt覺n覺 kullanaca覺z
Daha 繹nce olduu gibi ayn覺 MINDS-14 veri setini kullanarak fatura 繹demeyle ilgili bir soru sormak.

Balamak i癟in veri k羹mesini y羹kleyin ve [Bir boru hatt覺yla ses s覺n覺fland覺rmas覺](audio_classification_pipeline) b繹l羹m羹nde a癟覺kland覺覺 gibi 16 kHz'e 繹rnekleyin.
eer bunu hen羹z yapmad覺ysan覺z.

Bir ses kayd覺n覺 transkript etmek i癟in  Transformers'覺n automatic-speech-recognition (otomatik konuma tan覺ma) i ak覺覺n覺 kullanabiliriz. 襤te bu i ak覺覺n覺 olutural覺m:

```py
from transformers import pipeline

asr = pipeline("automatic-speech-recognition")
```

Daha sonra veri k羹mesinden bir 繹rnek al覺p ham verilerini ard覺覺k d羹zene aktaraca覺z:

```py
example = minds[0]
asr(example["audio"]["array"])
```

**覺kt覺:**
```out
{"text": "ELEKTR襤K FATURAMI KODUMLA DEMEK 襤ST襤YORUM LTFEN YARDIMCI OLAB襤L襤R M襤S襤N襤Z?"}
```

Bu 癟覺kt覺y覺, bu 繹rnein ger癟ek transkripsiyonuyla kar覺lat覺ral覺m:

```py
example["english_transcription"]
```

**覺kt覺:**
```out
"Elektrik faturam覺 kart覺mla 繹demek istiyorum l羹tfen yard覺mc覺 olur musunuz?"
```

Model, sesi transkribe etmede olduk癟a iyi bir i 癟覺karm覺 gibi g繹r羹n羹yor! Orijinal transkriptle kar覺lat覺r覺ld覺覺nda sadece bir kelimeyi ("card") yanl覺 alm覺, bu da konumac覺n覺n s覺kl覺kla "r" harfini sessiz olarak s繹yledii Avustralya aksan覺n覺 d羹羹n羹rsek olduk癟a iyi bir sonu癟. Bununla birlikte, bir sonraki elektrik faturan覺z覺 bir bal覺kla 繹demeyi denemenizi tavsiye etmem!

Varsay覺lan olarak, bu ilem hatt覺 襤ngilizce i癟in otomatik konuma tan覺ma i癟in eitilmi bir model kullan覺r;
bu 繹rnek. MINDS-14'羹n dier alt k羹melerini farkl覺 dillerde yazmay覺 denemek isterseniz, 繹nceden eitilmi bir kaynak bulabilirsiniz.
ASR modeli [ Hub'da](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&language=fr&sort=downloads).
Model listesini 繹nce g繹reve, ard覺ndan dile g繹re filtreleyebilirsiniz. Beendiiniz modeli bulduunuzda ad覺n覺 u ekilde iletin:
boru hatt覺na y繹nelik "model" arg羹man覺.

Bunu MINDS-14'羹n Almanya'daki b繹l羹nmesi i癟in deneyelim. "de-DE" alt k羹mesini y羹kleyin:

```py
from datasets import load_dataset
from datasets import Audio

minds = load_dataset("PolyAI/minds14", name="de-DE", split="train")
minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
```

Bir 繹rnek al覺n ve transkripsiyonun ne olmas覺 gerektiini g繹r羹n:

```py
example = minds[0]
example["transcription"]
```

**覺kt覺:**
```out
"ich m繹chte gerne Geld auf mein Konto einzahlen"
```

 Hub'da Almanca i癟in 繹nceden eitilmi bir ASR modeli bulun, bir ilem hatt覺 oluturun ve 繹rnei yaz覺ya d繹k羹n:

```py
from transformers import pipeline

asr = pipeline("automatic-speech-recognition", model="maxidl/wav2vec2-large-xlsr-german")
asr(example["audio"]["array"])
```

**覺kt覺:**
```out
{"text": "ich m繹chte gerne geld auf mein konto einzallen"}
```

Also, stimmt's!

Kendi g繹revinizi 癟繹zmeye 癟al覺覺rken, bu 羹nitede g繹sterdiimiz gibi basit bir ilem hatt覺yla balamak deerli bir ad覺md覺r.
癟eitli avantajlar sunan ara癟:
- G繹revinizi zaten ger癟ekten iyi 癟繹zen, size bolca zaman kazand覺ran, 繹nceden eitilmi bir model mevcut olabilir.
- pipeline() sizin i癟in t羹m 繹n/son ilemleri halleder, b繹ylece verileri bir model i癟in doru formata getirme konusunda endielenmenize gerek kalmaz
- Sonu癟 ideal deilse bile bu size gelecekte yapaca覺n覺z ince ayarlar i癟in h覺zl覺 bir temel salar.
- zel verileriniz 羹zerinde bir modele ince ayar yapt覺覺n覺zda ve bunu Hub'da paylat覺覺n覺zda, yapay zekay覺 daha eriilebilir hale getiren "pipeline()" y繹ntemi arac覺l覺覺yla t羹m topluluk onu h覺zl覺 ve zahmetsizce kullanabilecektir.

