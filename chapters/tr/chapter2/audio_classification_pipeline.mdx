# UÃ§tan uca ses sÄ±nÄ±flandÄ±rmasÄ±


Ses sÄ±nÄ±flandÄ±rmasÄ±, iÃ§eriÄŸine gÃ¶re bir ses kaydÄ±na bir veya daha fazla etiket atamayÄ± iÃ§erir. Etiketler mÃ¼zik, konuÅŸma veya gÃ¼rÃ¼ltÃ¼ gibi farklÄ± ses kategorilerine veya kuÅŸ ÅŸarkÄ±sÄ± veya araba motoru sesleri gibi daha spesifik kategorilere karÅŸÄ±lÄ±k gelebilir.

En popÃ¼ler ses transformatÃ¶rlerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair ayrÄ±ntÄ±lara dalmadan ve Ã¶zel bir modele ince ayar yapmadan Ã¶nce, yalnÄ±zca birkaÃ§ satÄ±r kodla ses sÄ±nÄ±flandÄ±rmasÄ± iÃ§in kullanÄ±ma hazÄ±r, Ã¶nceden eÄŸitilmiÅŸ bir modeli nasÄ±l kullanabileceÄŸinizi gÃ¶relim. TransformatÃ¶rler.



Hadi devam edelim ve Ã¶nceki Ã¼nitede keÅŸfettiÄŸiniz aynÄ± [MINDS-14](https://huggingface.co/datasets/PolyAI/minds14) veri kÃ¼mesini kullanalÄ±m. HatÄ±rlarsanÄ±z MINDS-14, e-bankacÄ±lÄ±k sistemine soru soran kiÅŸilerin Ã§eÅŸitli dil ve lehÃ§elerdeki kayÄ±tlarÄ±nÄ± iÃ§eriyor ve her kayÄ±t iÃ§in bir â€œintent_classâ€a sahip. KayÄ±tlarÄ± Ã§aÄŸrÄ±nÄ±n amacÄ±na gÃ¶re sÄ±nÄ±flandÄ±rabiliriz.

Daha Ã¶nce olduÄŸu gibi, boru hattÄ±nÄ± denemek iÃ§in verinin "en-AU" alt kÃ¼mesini yÃ¼kleyerek baÅŸlayalÄ±m ve bunu Ã§oÄŸu konuÅŸma modelinin gerektirdiÄŸi 16kHz Ã¶rnekleme hÄ±zÄ±na Ã¶rnekleyelim.

```py
from datasets import load_dataset
from datasets import Audio

minds = load_dataset("PolyAI/minds14", name="en-AU", split="train")
minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
```


Bir ses kaydÄ±nÄ± bir dizi sÄ±nÄ±fa sÄ±nÄ±flandÄ±rmak iÃ§in ğŸ¤— Transformers'Ä±n audio-classification (ses sÄ±nÄ±flandÄ±rma) iÅŸ akÄ±ÅŸÄ±nÄ± kullanabiliriz. Bizim durumumuzda, amaÃ§ sÄ±nÄ±flandÄ±rmasÄ± iÃ§in ince ayar yapÄ±lmÄ±ÅŸ bir modele ihtiyacÄ±mÄ±z var ve Ã¶zellikle MINDS-14 veri kÃ¼mesinde ince ayar yapÄ±lmÄ±ÅŸ bir modele ihtiyacÄ±mÄ±z var. Neyse ki, Hub'da tam olarak bu iÅŸi yapan bir model bulunuyor! Onu pipeline() iÅŸlevini kullanarak yÃ¼kleyelim:

```py
from transformers import pipeline

classifier = pipeline(
    "audio-classification",
    model="anton-l/xtreme_s_xlsr_300m_minds14",
)
```

Bu ardÄ±ÅŸÄ±k dÃ¼zen, ses verilerinin bir NumPy dizisi olmasÄ±nÄ± bekler. Ham ses verilerinin tÃ¼m Ã¶n iÅŸlemleri bizim iÃ§in boru hattÄ± tarafÄ±ndan uygun bir ÅŸekilde gerÃ§ekleÅŸtirilecektir. Denemek iÃ§in bir Ã¶rnek seÃ§elim:

```py
example = minds[0]
```

Veri kÃ¼mesinin yapÄ±sÄ±nÄ± hatÄ±rlarsanÄ±z, ham ses verileri `["audio"]["array"]` altÄ±nda bir NumPy dizisinde saklanÄ±r, hadi bunu doÄŸrudan `sÄ±nÄ±flandÄ±rÄ±cÄ±ya' aktaralÄ±m:

```py
classifier(example["audio"]["array"])
```

**Ã‡Ä±ktÄ±:**
```out
[
    {"score": 0.9631525278091431, "label": "pay_bill"},
    {"score": 0.02819698303937912, "label": "freeze"},
    {"score": 0.0032787492964416742, "label": "card_issues"},
    {"score": 0.0019414445850998163, "label": "abroad"},
    {"score": 0.0008378693601116538, "label": "high_value_payment"},
]
```

Model, arayan kiÅŸinin faturasÄ±nÄ± Ã¶demeyi Ã¶ÄŸrenmek istediÄŸinden oldukÃ§a emin. Bu Ã¶rnek iÃ§in gerÃ§ek etiketin ne olduÄŸunu gÃ¶relim:

```py
id2label = minds.features["intent_class"].int2str
id2label(example["intent_class"])
```

**Ã‡Ä±ktÄ±:**
```out
"pay_bill"
```

Harika! Tahmin edilen etiket doÄŸruydu! Burada, ihtiyacÄ±mÄ±z olan kesin etiketleri sÄ±nÄ±flandÄ±rabilen bir model bulmak ÅŸanslÄ±ydÄ±k. SÄ±nÄ±flandÄ±rma gÃ¶revi ile uÄŸraÅŸÄ±rken, bir Ã¶nceden eÄŸitilmiÅŸ modelin sÄ±nÄ±f kÃ¼mesinin tam olarak modelin ayÄ±rt etmesini istediÄŸiniz sÄ±nÄ±flarla aynÄ± olmadÄ±ÄŸÄ± birÃ§ok durum vardÄ±r. Bu durumda, bir Ã¶nceden eÄŸitilmiÅŸ modeli tam olarak sÄ±nÄ±f etiketleriniz kÃ¼mesine "ayarlamak" iÃ§in ince ayar yapabilirsiniz. Bu iÅŸlemi gelecek Ã¼nitelerde nasÄ±l yapacaÄŸÄ±mÄ±zÄ± Ã¶ÄŸreneceÄŸiz. Åimdi, konuÅŸma iÅŸleme alanÄ±nda yaygÄ±n bir baÅŸka gÃ¶rev olan otomatik konuÅŸma tanÄ±ma gÃ¶revine bir gÃ¶z atalÄ±m.
