# Carregue e explore um dataset de √°udio

Neste curso, utilizaremos a biblioteca ü§ó Datasets (Hugging Face Datasets) para trabalhar com datasets de √°udio. ü§ó Datasets √© uma biblioteca open source para baixar e preparar datasets de todas as modalidades, incluindo √°udio. A biblioteca oferece f√°cil acesso a uma sele√ß√£o √∫nica  de datasets de machine learning dispon√≠veis publicamente no Hugging Face Hub. Al√©m disso, ü§ó Datasets inclui v√°rias funcionalidades adaptadas para datasets de √°udio que simplificam o trabalho  tanto para pesquisadores quanto para praticantes.

Para come√ßar a trabalhar com datasets de √°udio certifique-se de ter a biblioteca ü§ó Datasets instalada:

```bash
pip install datasets[audio]
```

Uma das principais caracter√≠sticas da ü§ó Datasets √© a capacidade de baixar e preparar um dataset com apenas uma linha de c√≥digo Python usando a fun√ß√£o `load_dataset()`.

Vamos carregar e explorar um dataset de √°udio chamado [MINDS-14](https://huggingface.co/datasets/PolyAI/minds14), que cont√©m grava√ß√µes de pessoas fazendo perguntas a um sistema de e-banking em v√°rios idiomas e dialetos.

Para carregar o dataset MINDS-14, precisamos copiar o identificador do dataset no Hub (`PolyAI/minds14`) e pass√°-lo para a fun√ß√£o `load_dataset`. Tamb√©m especificaremos que estamos interessados apenas no subconjunto Australiano dos dados, e limit√°-lo ao traning split (a parte dos dados somente para treino):

```py
from datasets import load_dataset

minds = load_dataset("PolyAI/minds14", name="en-AU", split="train")
minds
```

**Sa√≠da:**
```out
Dataset(
    {
        features: [
            "path",
            "audio",
            "transcription",
            "english_transcription",
            "intent_class",
            "lang_id",
        ],
        num_rows: 654,
    }
)
```

O dataset cont√©m 654 arquivos de √°udio, cada um possui os seguintes campos (features): transcri√ß√£o, uma tradu√ß√£o para o ingl√™s e um r√≥tulo indicando o motivo da pergunta da pessoa. A coluna audio cont√©m os dados brutos do √°udio (sem processamento). Vamos dar uma olhada mais de perto em um dos exemplos:

```py
example = minds[0]
example
```

**Sa√≠da:**
```out
{
    "path": "/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-AU~PAY_BILL/response_4.wav",
    "audio": {
        "path": "/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-AU~PAY_BILL/response_4.wav",
        "array": array(
            [0.0, 0.00024414, -0.00024414, ..., -0.00024414, 0.00024414, 0.0012207],
            dtype=float32,
        ),
        "sampling_rate": 8000,
    },
    "transcription": "I would like to pay my electricity bill using my card can you please assist",
    "english_transcription": "I would like to pay my electricity bill using my card can you please assist",
    "intent_class": 13,
    "lang_id": 2,
}
```

Note que a coluna audio cont√©m v√°rias features (campos ou caracter√≠sticas). Aqui est√° uma descri√ß√£o delas:
* `path`: o caminho para o arquivo de √°udio (`*.wav` neste caso).
* `array`: Os dados de √°udio decodificados, representados como um array unidimensional NumPy.
* `sampling_rate`: A taxa de amostragem do arquivo de √°udio (8.000 Hz neste exemplo).

O `intent_class` √© uma categoria para classificar a grava√ß√£o de √°udio. Para converter este n√∫mero em algo mais significativo, podemos usar o m√©todo `int2str()`:

```py
id2label = minds.features["intent_class"].int2str
id2label(example["intent_class"])
```

**Sa√≠da:**
```out
"pay_bill"
```

Se voc√™ olhar o campo transcription (em ingl√™s), vai ver que o arquivo de √°udio de fato gravou uma pessoa fazendo uma pergunta sobre o pagamento de uma conta.

Se voc√™ planeja treinar um classificador de √°udio com este subconjunto dos dados, voc√™ n√£o vai precisar, necessariamente, de todos os campos. Por exemplo, o `lang_id` vai ter o mesmo valor para todos os exemplos, e n√£o tem utilidade. A coluna `english_transcription` provavelmente ser√° uma c√≥pia de `transcription` neste subconjunto, ent√£o podemos remov√™-las tranquilamente.

Voc√™ pode facilmente remover campos (features) irrelevantes usando o m√©todo `remove_columns` da ü§ó Datasets:

```py
columns_to_remove = ["lang_id", "english_transcription"]
minds = minds.remove_columns(columns_to_remove)
minds
```

**Sa√≠da:**
```out
Dataset({features: ["path", "audio", "transcription", "intent_class"], num_rows: 654})
```

Agora que carregamos e inspecionamos o conte√∫do bruto do dataset, vamos ouvir alguns exemplos! Usaremos as propriedades `Blocks` e `Audio` do `Gradio` para decodificar algumas amostras aleat√≥rias:

```py
import gradio as gr


def generate_audio():
    example = minds.shuffle()[0]
    audio = example["audio"]
    return (
        audio["sampling_rate"],
        audio["array"],
    ), id2label(example["intent_class"])


with gr.Blocks() as demo:
    with gr.Column():
        for _ in range(4):
            audio, label = generate_audio()
            output = gr.Audio(audio, label=label)

demo.launch(debug=True)
```

Se voc√™ quiser, tamb√©m pode visualizar alguns dos exemplos. Vamos plotar a forma de onda para o primeiro exemplo.

```py
import librosa
import matplotlib.pyplot as plt
import librosa.display

array = example["audio"]["array"]
sampling_rate = example["audio"]["sampling_rate"]

plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/waveform_unit1.png" alt="Plot da forma de onda">
</div>

Sua vez de tentar! Baixe outro dialeto ou idioma do dataset MINDS-14, ou√ßa e visualize alguns exemplos para ter uma no√ß√£o da variedade do dataset inteiro. Voc√™ pode encontrar a lista completa de idiomas dispon√≠veis [aqui](https://huggingface.co/datasets/PolyAI/minds14).
