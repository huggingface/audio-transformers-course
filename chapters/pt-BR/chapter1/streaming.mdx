# Streaming de dados de √°udio

Um dos maiores desafios enfrentados com datasets de √°udio √© o seu tamanho imenso. Um √∫nico minuto de √°udio de qualidade de CD n√£o comprimido (44,1kHz, 16-bit) ocupa um pouco mais de 5 MB de armazenamento. Normalmente, um dataset de √°udio cont√©m horas de grava√ß√µes.

Nas se√ß√µes anteriores, usamos um subconjunto muito pequeno do dataset de √°udio MINDS-14, no entanto, datasets de √°udio t√≠picos s√£o muito maiores. Por exemplo, a configura√ß√£o `xs` (a menor) do [GigaSpeech do SpeechColab](https://huggingface.co/datasets/speechcolab/gigaspeech) cont√©m apenas 10 horas de dados de treinamento, mas ocupa mais de 13GB de espa√ßo de armazenamento para download e prepara√ß√£o. Ent√£o, o que acontece quando queremos treinar em um conjunto maior? A configura√ß√£o completa `xl` do mesmo dataset cont√©m 10.000 horas de dados de treinamento, exigindo mais de 1TB de espa√ßo de armazenamento. Para a maioria de n√≥s, isso excede em muito as especifica√ß√µes de um disco comum. Precisamos gastar e comprar armazenamento adicional? Ou existe uma maneira de treinarmos nesses datasets sem restri√ß√µes de espa√ßo em disco?

ü§ó Datasets nos salva oferecendo o [modo de streaming](https://huggingface.co/docs/datasets/stream). O Streaming nos permite carregar os dados progressivamente √† medida que iteramos sobre o dataset. Em vez de baixar o dataset inteiro de uma vez, carregamos um exemplo de cada vez. Iteramos sobre o dataset, carregando e preparando exemplos na hora quando s√£o necess√°rios. Desta forma, s√≥ carregamos os exemplos que estamos usando, e n√£o os que n√£o estamos! Uma vez que terminamos com uma amostra de exemplo, continuamos iterando sobre o dataset e carregamos o pr√≥ximo.

O modo de streaming tem tr√™s vantagens principais sobre o download do dataset inteiro de uma vez:

* Espa√ßo em disco: os exemplos s√£o carregados na mem√≥ria um por um √† medida que iteramos sobre o dataset. Como os dados n√£o s√£o baixados localmente, n√£o h√° requisitos de espa√ßo em disco, ent√£o voc√™ pode usar datasets de tamanho arbitr√°rio.
* Tempo de download e processamento: datasets de √°udio s√£o grandes e precisam de uma quantidade significativa de tempo para serem baixados e processados. Com streaming, o carregamento e processamento √© feito na hora, o que significa que voc√™ pode come√ßar a usar o dataset assim que o primeiro exemplo estiver pronto.
* Experimenta√ß√£o f√°cil: voc√™ pode experimentar em um punhado de exemplos para verificar se o seu script funciona sem ter que baixar o dataset inteiro.

H√° uma ressalva para o modo de streaming. Ao baixar um dataset completo sem streaming, tanto os dados brutos quanto os dados processados s√£o salvos localmente no disco. Se quisermos reutilizar este dataset, podemos carregar diretamente os dados processados do disco, pulando as etapas de download e processamento. Consequentemente, s√≥ temos que realizar as opera√ß√µes de download e processamento uma vez, ap√≥s o que podemos reutilizar os dados preparados.

Com o modo de streaming, os dados n√£o s√£o baixados para o disco. Assim, nem os dados baixados nem os pr√©-processados s√£o armazenados em cache. Se quisermos reutilizar o dataset, as etapas de streaming devem ser repetidas, com os arquivos de √°udio carregados e processados na hora novamente. Por essa raz√£o, √© aconselh√°vel baixar datasets que voc√™ provavelmente usar√° v√°rias vezes.

Como voc√™ pode habilitar o modo de streaming? F√°cil! Basta definir `streaming=True` quando voc√™ carregar seu dataset. O resto ser√° cuidado para voc√™:

```py
gigaspeech = load_dataset("speechcolab/gigaspeech", "xs", streaming=True)
```

Assim como aplicamos etapas de pr√©-processamento a um subconjunto baixado do MINDS-14, voc√™ pode fazer o mesmo pr√©-processamento com um dataset em streaming exatamente da mesma maneira.

A √∫nica diferen√ßa √© que voc√™ n√£o pode mais acessar amostras individuais usando indexa√ß√£o do Python (ou seja, `gigaspeech["train"][sample_idx]`). Em vez disso, voc√™ tem que iterar sobre o dataset. Aqui est√° como voc√™ pode acessar um exemplo ao transmitir um dataset:

```py
next(iter(gigaspeech["train"]))
```

**Sa√≠da:**
```out
{
    "segment_id": "YOU0000000315_S0000660",
    "speaker": "N/A",
    "text": "AS THEY'RE LEAVING <COMMA> CAN KASH PULL ZAHRA ASIDE REALLY QUICKLY <QUESTIONMARK>",
    "audio": {
        "path": "xs_chunks_0000/YOU0000000315_S0000660.wav",
        "array": array(
            [0.0005188, 0.00085449, 0.00012207, ..., 0.00125122, 0.00076294, 0.00036621]
        ),
        "sampling_rate": 16000,
    },
    "begin_time": 2941.89,
    "end_time": 2945.07,
    "audio_id": "YOU0000000315",
    "title": "Return to Vasselheim | Critical Role: VOX MACHINA | Episode 43",
    "url": "https://www.youtube.com/watch?v=zr2n1fLVasU",
    "source": 2,
    "category": 24,
    "original_full_path": "audio/youtube/P0004/YOU0000000315.opus",
}
```

Se voc√™ gostaria de visualizar v√°rios exemplos de um grande dataset, use o `take()` para obter os primeiros n elementos. Vamos pegar os dois primeiros exemplos no dataset gigaspeech:

```py
gigaspeech_head = gigaspeech["train"].take(2)
list(gigaspeech_head)
```

**Sa√≠da:**
```out
[
    {
        "segment_id": "YOU0000000315_S0000660",
        "speaker": "N/A",
        "text": "AS THEY'RE LEAVING <COMMA> CAN KASH PULL ZAHRA ASIDE REALLY QUICKLY <QUESTIONMARK>",
        "audio": {
            "path": "xs_chunks_0000/YOU0000000315_S0000660.wav",
            "array": array(
                [
                    0.0005188,
                    0.00085449,
                    0.00012207,
                    ...,
                    0.00125122,
                    0.00076294,
                    0.00036621,
                ]
            ),
            "sampling_rate": 16000,
        },
        "begin_time": 2941.89,
        "end_time": 2945.07,
        "audio_id": "YOU0000000315",
        "title": "Return to Vasselheim | Critical Role: VOX MACHINA | Episode 43",
        "url": "https://www.youtube.com/watch?v=zr2n1fLVasU",
        "source": 2,
        "category": 24,
        "original_full_path": "audio/youtube/P0004/YOU0000000315.opus",
    },
    {
        "segment_id": "AUD0000001043_S0000775",
        "speaker": "N/A",
        "text": "SIX TOMATOES <PERIOD>",
        "audio": {
            "path": "xs_chunks_0000/AUD0000001043_S0000775.wav",
            "array": array(
                [
                    1.43432617e-03,
                    1.37329102e-03,
                    1.31225586e-03,
                    ...,
                    -6.10351562e-05,
                    -1.22070312e-04,
                    -1.83105469e-04,
                ]
            ),
            "sampling_rate": 16000,
        },
        "begin_time": 3673.96,
        "end_time": 3675.26,
        "audio_id": "AUD0000001043",
        "title": "Asteroid of Fear",
        "url": "http//www.archive.org/download/asteroid_of_fear_1012_librivox/asteroid_of_fear_1012_librivox_64kb_mp3.zip",
        "source": 0,
        "category": 28,
        "original_full_path": "audio/audiobook/P0011/AUD0000001043.opus",
    },
]
```

O modo de streaming pode levar sua pesquisa para o pr√≥ximo n√≠vel: n√£o apenas os maiores datasets est√£o acess√≠veis para voc√™, mas voc√™ pode facilmente avaliar sistemas atrav√©s de v√°rios datasets de uma s√≥ vez sem se preocupar com o espa√ßo em disco. Comparado √† avalia√ß√£o em um √∫nico dataset, a avalia√ß√£o em v√°rios datasets fornece uma m√©trica melhor para as habilidades de generaliza√ß√£o de um sistema de reconhecimento de fala (c.f. End-to-end Speech Benchmark (ESB)).
