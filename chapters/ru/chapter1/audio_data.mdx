# –í–≤–µ–¥–µ–Ω–∏–µ –≤ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ

–ü–æ —Å–≤–æ–µ–π –ø—Ä–∏—Ä–æ–¥–µ –∑–≤—É–∫–æ–≤–∞—è –≤–æ–ª–Ω–∞ —è–≤–ª—è–µ—Ç—Å—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º —Å–∏–≥–Ω–∞–ª–æ–º, —Ç–æ –µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–µ —á–∏—Å–ª–æ –∑–Ω–∞—á–µ–Ω–∏–π —Å–∏–≥–Ω–∞–ª–∞ –∑–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è.
–≠—Ç–æ —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ–∂–∏–¥–∞—é—Ç –∫–æ–Ω–µ—á–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã. –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–¥–∞—á–∏ —Å–∏–≥–Ω–∞–ª–∞ —Ü–∏—Ñ—Ä–æ–≤—ã–º–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏,
–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–∞—è –∑–≤—É–∫–æ–≤–∞—è –≤–æ–ª–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ —Ä—è–¥ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –Ω–∞–∑—ã–≤–∞–µ–º—ã—Ö —Ü–∏—Ñ—Ä–æ–≤—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º.

–ï—Å–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –ª—é–±–æ–º—É –Ω–∞–±–æ—Ä—É –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö, —Ç–æ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ —Ü–∏—Ñ—Ä–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å–æ –∑–≤—É–∫–æ–≤—ã–º–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ–º –∏–ª–∏ –º—É–∑—ã–∫–æ–π.
–í—ã –º–æ–∂–µ—Ç–µ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤, —Ç–∞–∫–∏–µ –∫–∞–∫ `.wav` (Waveform Audio File), `.flac` (Free Lossless Audio Codec),
`.mp3` (MPEG-1 Audio Layer 3). –≠—Ç–∏ —Ñ–æ—Ä–º–∞—Ç—ã —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è –≥–ª–∞–≤–Ω—ã–º –æ–±—Ä–∞–∑–æ–º —Å–ø–æ—Å–æ–±–æ–º —Å–∂–∞—Ç–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞.

–†–∞—Å—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –º—ã –ø—Ä–∏—Ö–æ–¥–∏–º –æ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –∫ —Ç–∞–∫–æ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é. –°–Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–æ–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è
–º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–º, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∑–≤—É–∫–æ–≤—ã–µ –≤–æ–ª–Ω—ã –≤ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–π —Å–∏–≥–Ω–∞–ª. –ó–∞—Ç–µ–º —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–π —Å–∏–≥–Ω–∞–ª –æ—Ü–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é
–ê–Ω–∞–ª–æ–≥–æ-—Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø—É—Ç–µ–º –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏.

## –í—ã–±–æ—Ä–∫–∞ –∏ —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

–í—ã–±–æ—Ä–∫–∞ (—Å—ç–º–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏—è) - —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –∏–∑–º–µ—Ä–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —à–∞–≥–æ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏. –í—ã–±–æ—Ä–æ—á–Ω–∞—è —Ñ–æ—Ä–º–∞ —Å–∏–≥–Ω–∞–ª–∞ —è–≤–ª—è–µ—Ç—Å—è _–¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–π_,
–ø–æ—Å–∫–æ–ª—å–∫—É —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω–µ—á–Ω–æ–µ —á–∏—Å–ª–æ –∑–Ω–∞—á–µ–Ω–∏–π —Å–∏–≥–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –≤—Ä–µ–º–µ–Ω–∏.

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/Signal_Sampling.png" alt="–ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞">
</div>

*–ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è –∏–∑ —Å—Ç–∞—Ç—å–∏ –í–∏–∫–∏–ø–µ–¥–∏–∏: [–°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤)](https://en.wikipedia.org/wiki/Sampling_(signal_processing))*

**–ß–∞—Å—Ç–æ—Ç–∞ –≤—ã–±–æ—Ä–∫–∏** (—Ç–∞–∫–∂–µ –Ω–∞–∑—ã–≤–∞–µ–º–∞—è —á–∞—Å—Ç–æ—Ç–æ–π –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏) - —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±–æ—Ä–æ–∫, —Å–¥–µ–ª–∞–Ω–Ω—ã—Ö –∑–∞ –æ–¥–Ω—É —Å–µ–∫—É–Ω–¥—É, –∏ –∏–∑–º–µ—Ä—è–µ—Ç—Å—è –≤
–≥–µ—Ä—Ü–∞—Ö (–ì—Ü). –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ CD-–∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 44 100 –ì—Ü, —Ç–æ –µ—Å—Ç—å –≤—ã–±–æ—Ä–∫–∏ –¥–µ–ª–∞—é—Ç—Å—è
44 100 —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É. –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∑–≤—É–∫–∞ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 192 000 –ì—Ü –∏–ª–∏ 192 –∫–ì—Ü. –û–±—ã—á–Ω–æ
—á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Ä–µ—á–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 16 000 –ì—Ü –∏–ª–∏ 16 –∫–ì—Ü.

–í—ã–±–æ—Ä —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–∏–≤—ã—Å—à—É—é —á–∞—Å—Ç–æ—Ç—É, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∞ –∏–∑ —Å–∏–≥–Ω–∞–ª–∞. –≠—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–∞–∫–∂–µ,
–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –∫–∞–∫ –ø—Ä–µ–¥–µ–ª –ù–∞–π–∫–≤–∏—Å—Ç–∞, –∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–æ–≤–Ω–æ –ø–æ–ª–æ–≤–∏–Ω—É —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏. –°–ª—ã—à–∏–º—ã–µ —á–∞—Å—Ç–æ—Ç—ã –≤ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Ä–µ—á–∏ –ª–µ–∂–∞—Ç –Ω–∏–∂–µ 8 –∫–ì—Ü,
–ø–æ—ç—Ç–æ–º—É –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ —Ä–µ—á–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 16 –∫–ì—Ü. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–π —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏
—Ç–æ–ª—å–∫–æ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —É–≤–µ–ª–∏—á–µ–Ω–∏—é –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–∞–∫–∏—Ö —Ñ–∞–π–ª–æ–≤. –° –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏—è –∑–≤—É–∫–∞ –ø—Ä–∏ —Å–ª–∏—à–∫–æ–º
–Ω–∏–∑–∫–æ–π —á–∞—Å—Ç–æ—Ç–µ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –ø–æ—Ç–µ—Ä–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –†–µ—á—å, –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å —á–∞—Å—Ç–æ—Ç–æ–π 8 –∫–ì—Ü, –±—É–¥–µ—Ç –∑–≤—É—á–∞—Ç—å –ø—Ä–∏–≥–ª—É—à–µ–Ω–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã
–Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞—Ö–≤–∞—á–µ–Ω—ã –ø—Ä–∏ —Ç–∞–∫–æ–π —á–∞—Å—Ç–æ—Ç–µ.

–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ –Ω–∞–¥ –ª—é–±–æ–π –∞—É–¥–∏–æ –∑–∞–¥–∞—á–µ–π –≤–∞–∂–Ω–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã –∑–≤—É–∫–∞ –≤ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —á–∞—Å—Ç–æ—Ç—É –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏.
–ï—Å–ª–∏ –≤—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏, —Ç–æ —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —á–∞—Å—Ç–æ—Ç–µ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
–¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–∞ –º–æ–¥–µ–ª—å. –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏
–≤—ã–±–æ—Ä–∫–∞–º–∏ –∑–≤—É–∫–∞, —á—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä: 5-—Å–µ–∫—É–Ω–¥–Ω—ã–π –∑–≤—É–∫ –ø—Ä–∏ —á–∞—Å—Ç–æ—Ç–µ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
16 000 –ì—Ü –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ —Å–µ—Ä–∏–∏ –∏–∑ 80 000 –∑–Ω–∞—á–µ–Ω–∏–π, –∞ —Ç–æ—Ç –∂–µ 5-—Å–µ–∫—É–Ω–¥–Ω—ã–π –∑–≤—É–∫ –ø—Ä–∏ —á–∞—Å—Ç–æ—Ç–µ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
8 000 –ì—Ü –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ —Å–µ—Ä–∏–∏ –∏–∑ 40 000 –∑–Ω–∞—á–µ–Ω–∏–π. –ú–æ–¥–µ–ª–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, —Ä–µ—à–∞—é—â–∏–µ –∞—É–¥–∏–æ–∑–∞–¥–∞—á–∏, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
–∏ –ø–æ–ª–∞–≥–∞—é—Ç—Å—è –Ω–∞ –º–µ—Ö–∞–Ω–∏–∑–º—ã –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ –∏–ª–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é. –ü–æ—Å–∫–æ–ª—å–∫—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑–ª–∏—á–Ω—ã –¥–ª—è
–∞—É–¥–∏–æ–ø—Ä–∏–º–µ—Ä–æ–≤ —Å —Ä–∞–∑–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏, —Ç–æ –º–æ–¥–µ–ª—è–º –±—É–¥–µ—Ç —Å–ª–æ–∂–Ω–æ –æ–±–æ–±—â–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏.
**–ü–µ—Ä–µ–¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏—è** - —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è —á–∞—Å—Ç–æ—Ç –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏, —è–≤–ª—è—é—â–∏–π—Å—è —á–∞—Å—Ç—å—é [–ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞](preprocessing#resampling-the-audio-data) –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö.

## –ê–º–ø–ª–∏—Ç—É–¥–∞ –∏ –±–∏—Ç–æ–≤–∞—è –≥–ª—É–±–∏–Ω–∞

–í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –≥–æ–≤–æ—Ä–∏—Ç –æ —Ç–æ–º, –∫–∞–∫ —á–∞—Å—Ç–æ –±–µ—Ä—É—Ç—Å—è –æ–±—Ä–∞–∑—Ü—ã, –∫–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ –∫–∞–∂–¥–æ–º –æ–±—Ä–∞–∑—Ü–µ?

–ó–≤—É–∫ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–≤–ª–µ–Ω–∏—è –≤–æ–∑–¥—É—Ö–∞ –Ω–∞ —á–∞—Å—Ç–æ—Ç–∞—Ö, —Å–ª—ã—à–∏–º—ã—Ö —á–µ–ª–æ–≤–µ–∫–æ–º. –ê–º–ø–ª–∏—Ç—É–¥–∞** –∑–≤—É–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç
—É—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–æ–≤–æ–≥–æ –¥–∞–≤–ª–µ–Ω–∏—è –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏ –∏–∑–º–µ—Ä—è–µ—Ç—Å—è –≤ –¥–µ—Ü–∏–±–µ–ª–∞—Ö (–¥–ë). –ú—ã –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞–µ–º –∞–º–ø–ª–∏—Ç—É–¥—É –∫–∞–∫ –≥—Ä–æ–º–∫–æ—Å—Ç—å.
–î–ª—è –ø—Ä–∏–º–µ—Ä–∞, –æ–±—ã—á–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 60 –¥–ë, –∞ —Ä–æ–∫-–∫–æ–Ω—Ü–µ—Ä—Ç –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏–≥–∞—Ç—å 125 –¥–ë, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–¥–µ–ª–æ–º 
–¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Å–ª—É—Ö–∞.

–í —Ü–∏—Ñ—Ä–æ–≤–æ–º –∞—É–¥–∏–æ –∫–∞–∂–¥—ã–π –æ–±—Ä–∞–∑–µ—Ü –∑–≤—É–∫–∞ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –∞–º–ø–ª–∏—Ç—É–¥—É –∑–≤—É–∫–æ–≤–æ–π –≤–æ–ª–Ω—ã –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏. **–ë–∏—Ç–æ–≤–∞—è –≥–ª—É–±–∏–Ω–∞** –æ–±—Ä–∞–∑—Ü–∞ –∑–≤—É–∫–∞
–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å –∫–∞–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø–∏—Å–∞–Ω–æ —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –∞–º–ø–ª–∏—Ç—É–¥—ã. –ß–µ–º –≤—ã—à–µ –±–∏—Ç–æ–≤–∞—è –≥–ª—É–±–∏–Ω–∞, —Ç–µ–º —Ç–æ—á–Ω–µ–µ
—Ü–∏—Ñ—Ä–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–±–ª–∏–∂–∞–µ—Ç—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –∑–≤—É–∫–æ–≤–æ–π –≤–æ–ª–Ω–µ.

–ù–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –±–∏—Ç–æ–≤—ã–µ –≥–ª—É–±–∏–Ω—ã –∑–≤—É–∫–∞ - 16 –∏ 24 –±–∏—Ç–∞. –ö–∞–∂–¥–∞—è –∏–∑ –Ω–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –¥–≤–æ–∏—á–Ω—ã–π —Ç–µ—Ä–º–∏–Ω, –æ–±–æ–∑–Ω–∞—á–∞—é—â–∏–π –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —à–∞–≥–æ–≤,
–Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –º–æ–∂–Ω–æ –∫–≤–∞–Ω—Ç–æ–≤–∞—Ç—å –∞–º–ø–ª–∏—Ç—É–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏ –µ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∏–∑ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –≤ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–µ: 65 536 —à–∞–≥–æ–≤ –¥–ª—è 16-–±–∏—Ç–Ω–æ–≥–æ –∑–≤—É–∫–∞,
–¥–ª—è 24-–±–∏—Ç–Ω–æ–≥–æ –∑–≤—É–∫–∞ - 16 777 216 —à–∞–≥–æ–≤. –ü–æ—Å–∫–æ–ª—å–∫—É –ø—Ä–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–≥–æ,
–ø—Ä–æ—Ü–µ—Å—Å –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –≤–Ω–æ—Å–∏—Ç —à—É–º. –ß–µ–º –≤—ã—à–µ –±–∏—Ç–æ–≤–∞—è –≥–ª—É–±–∏–Ω–∞, —Ç–µ–º –º–µ–Ω—å—à–µ —ç—Ç–æ—Ç —à—É–º –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ
—à—É–º –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è 16-–±–∏—Ç–Ω–æ–≥–æ –∑–≤—É–∫–∞ —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–∞–ª, —á—Ç–æ–±—ã –±—ã—Ç—å –Ω–µ—Å–ª—ã—à–∏–º—ã–º, –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–µ–π –±–∏—Ç–æ–≤–æ–π –≥–ª—É–±–∏–Ω—ã –æ–±—ã—á–Ω–æ
–Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.

You may also come across 32-bit audio. This stores the samples as floating-point values, whereas 16-bit and 24-bit audio
use integer samples. The precision of a 32-bit floating-point value is 24 bits, giving it the same bit depth as 24-bit audio.
Floating-point audio samples are expected to lie within the [-1.0, 1.0] range. Since machine learning models naturally
work on floating-point data, the audio must first be converted into floating-point format before it can be used to train
the model. We'll see how to do this in the next section on [Preprocessing](preprocessing).

Just as with continuous audio signals, the amplitude of digital audio is typically expressed in decibels (dB). Since
human hearing is logarithmic in nature ‚Äî our ears are more sensitive to small fluctuations in quiet sounds than in loud
sounds ‚Äî the loudness of a sound is easier to interpret if the amplitudes are in decibels, which are also logarithmic.
The decibel scale for real-world audio starts at 0 dB, which represents the quietest possible sound humans can hear, and
louder sounds have larger values. However, for digital audio signals, 0 dB is the loudest possible amplitude, while all
other amplitudes are negative. As a quick rule of thumb: every -6 dB is a halving of the amplitude, and anything below -60 dB
is generally inaudible unless you really crank up the volume.

## Audio as a waveform

You may have seen sounds visualized as a **waveform**, which plots the sample values over time and illustrates the changes
in the sound's amplitude. This is also known as the *time domain* representation of sound.

This type of visualization is useful for identifying specific features of the audio signal such as the timing of individual
sound events, the overall loudness of the signal, and any irregularities or noise present in the audio.

To plot the waveform for an audio signal, we can use a Python library called `librosa`:

```bash
pip install librosa
```

Let's take an example sound called "trumpet" that comes with the library:

```py
import librosa

array, sampling_rate = librosa.load(librosa.ex("trumpet"))
```

The example is loaded as a tuple of audio time series (here we call it `array`), and sampling rate (`sampling_rate`).
Let's take a look at this sound's waveform by using librosa's `waveshow()` function:

```py
import matplotlib.pyplot as plt
import librosa.display

plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/waveform_plot.png" alt="Waveform plot">
</div>

This plots the amplitude of the signal on the y-axis and time along the x-axis. In other words, each point corresponds
to a single sample value that was taken when this sound was sampled. Also note that librosa returns the audio as
floating-point values already, and that the amplitude values are indeed within the [-1.0, 1.0] range.

Visualizing the audio along with listening to it can be a useful tool for understanding the data you are working with.
You can see the shape of the signal, observe patterns, learn to spot noise or distortion. If you preprocess data in some
ways, such as normalization, resampling, or filtering, you can visually confirm that preprocessing steps have been applied as expected.
After training a model, you can also visualize samples where errors occur (e.g. in audio classification task) to debug
the issue.

## The frequency spectrum

Another way to visualize audio data is to plot the **frequency spectrum** of an audio signal, also known as the *frequency domain*
representation. The spectrum is computed using the discrete Fourier transform or DFT. It describes the individual frequencies
that make up the signal and how strong they are.

Let's plot the frequency spectrum for the same trumpet sound by taking the DFT using numpy's `rfft()` function. While it
is possible to plot the spectrum of the entire sound, it's more useful to look at a small region instead. Here we'll take
the DFT over the first 4096 samples, which is roughly the length of the first note being played:

```py
import numpy as np

dft_input = array[:4096]

# calculate the DFT
window = np.hanning(len(dft_input))
windowed_input = dft_input * window
dft = np.fft.rfft(windowed_input)

# get the amplitude spectrum in decibels
amplitude = np.abs(dft)
amplitude_db = librosa.amplitude_to_db(amplitude, ref=np.max)

# get the frequency bins
frequency = librosa.fft_frequencies(sr=sampling_rate, n_fft=len(dft_input))

plt.figure().set_figwidth(12)
plt.plot(frequency, amplitude_db)
plt.xlabel("Frequency (Hz)")
plt.ylabel("Amplitude (dB)")
plt.xscale("log")
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/spectrum_plot.png" alt="Spectrum plot">
</div>

This plots the strength of the various frequency components that are present in this audio segment. The frequency values are on
the x-axis, usually plotted on a logarithmic scale, while their amplitudes are on the y-axis.

The frequency spectrum that we plotted shows several peaks. These peaks correspond to the harmonics of the note that's
being played, with the higher harmonics being quieter. Since the first peak is at around 620 Hz, this is the frequency spectrum of an E‚ô≠ note.

The output of the DFT is an array of complex numbers, made up of real and imaginary components. Taking
the magnitude with `np.abs(dft)` extracts the amplitude information from the spectrogram. The angle between the real and
imaginary components provides the so-called phase spectrum, but this is often discarded in machine learning applications.

You used `librosa.amplitude_to_db()` to convert the amplitude values to the decibel scale, making it easier to see
the finer details in the spectrum. Sometimes people use the **power spectrum**, which measures energy rather than amplitude;
this is simply a spectrum with the amplitude values squared.

<Tip>
üí° In practice, people use the term FFT interchangeably with DFT, as the FFT or Fast Fourier Transform is the only efficient
way to calculate the DFT on a computer.
</Tip>

The frequency spectrum of an audio signal contains the exact same information as its waveform ‚Äî they are simply two different
ways of looking at the same data (here, the first 4096 samples from the trumpet sound). Where the waveform plots the amplitude
of the audio signal over time, the spectrum visualizes the amplitudes of the individual frequencies at a fixed point in time.

## Spectrogram

What if we want to see how the frequencies in an audio signal change? The trumpet plays several notes and they all have
different frequencies. The problem is that the spectrum only shows a frozen snapshot of the frequencies at a given instant.
The solution is to take multiple DFTs, each covering only a small slice of time, and stack the resulting spectra together
into a **spectrogram**.

A spectrogram plots the frequency content of an audio signal as it changes over time. It allows you to see time, frequency,
and amplitude all on one graph. The algorithm that performs this computation is the STFT or Short Time Fourier Transform.

The spectrogram is one of the most informative audio tools available to you. For example, when working with a music recording,
you can see the various instruments and vocal tracks and how they contribute to the overall sound. In speech, you can
identify different vowel sounds as each vowel is characterized by particular frequencies.

Let's plot a spectrogram for the same trumpet sound, using librosa's `stft()` and `specshow()` functions:

```py
import numpy as np

D = librosa.stft(array)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

plt.figure().set_figwidth(12)
librosa.display.specshow(S_db, x_axis="time", y_axis="hz")
plt.colorbar()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/spectrogram_plot.png" alt="Spectrogram plot">
</div>

In this plot, the x-axis represents time as in the waveform visualization but now the y-axis represents frequency in Hz.
The intensity of the color gives the amplitude or power of the frequency component at each point in time, measured in decibels (dB).

The spectrogram is created by taking short segments of the audio signal, typically lasting a few milliseconds, and calculating
the discrete Fourier transform of each segment to obtain its frequency spectrum. The resulting spectra are then stacked
together on the time axis to create the spectrogram. Each vertical slice in this image corresponds to a single frequency
spectrum, seen from the top. By default, `librosa.stft()` splits the audio signal into segments of 2048 samples, which
gives a good trade-off between frequency resolution and time resolution.

Since the spectrogram and the waveform are different views of the same data, it's possible to turn the spectrogram back
into the original waveform using the inverse STFT. However, this requires the phase information in addition to the amplitude
information. If the spectrogram was generated by a machine learning model, it typically only outputs the amplitudes. In
that case, we can use a phase reconstruction algorithm such as the classic Griffin-Lim algorithm, or using a neural network
called a vocoder, to reconstruct a waveform from the spectrogram.

Spectrograms aren't just used for visualization. Many machine learning models will take spectrograms as input ‚Äî as opposed
to waveforms ‚Äî and produce spectrograms as output.

Now that we know what a spectrogram is and how it's made, let's take a look at a variant of it widely used for speech processing: the mel spectrogram.

## Mel spectrogram

A mel spectrogram is a variation of the spectrogram that is commonly used in speech processing and machine learning tasks.
It is similar to a spectrogram in that it shows the frequency content of an audio signal over time, but on a different frequency axis.

In a standard spectrogram, the frequency axis is linear and is measured in hertz (Hz). However, the human auditory system
is more sensitive to changes in lower frequencies than higher frequencies, and this sensitivity decreases logarithmically
as frequency increases. The mel scale is a perceptual scale that approximates the non-linear frequency response of the human ear.

To create a mel spectrogram, the STFT is used just like before, splitting the audio into short segments to obtain a sequence
of frequency spectra. Additionally, each spectrum is sent through a set of filters, the so-called mel filterbank, to
transform the frequencies to the mel scale.

Let's see how we can plot a mel spectrogram using librosa's `melspectrogram()` function, which performs all of those steps for us:

```py
S = librosa.feature.melspectrogram(y=array, sr=sampling_rate, n_mels=128, fmax=8000)
S_dB = librosa.power_to_db(S, ref=np.max)

plt.figure().set_figwidth(12)
librosa.display.specshow(S_dB, x_axis="time", y_axis="mel", sr=sampling_rate, fmax=8000)
plt.colorbar()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface-course/audio-course-images/resolve/main/mel-spectrogram.png" alt="Mel spectrogram plot">
</div>


In the example above, `n_mels` stands for the number of mel bands to generate. The mel bands define a set of frequency
ranges that divide the spectrum into perceptually meaningful components, using a set of filters whose shape and spacing
are chosen to mimic the way the human ear responds to different frequencies. Common values for `n_mels` are 40 or 80. `fmax`
indicates the highest frequency (in Hz) we care about.

Just as with a regular spectrogram, it's common practice to express the strength of the mel frequency components in
decibels. This is commonly referred to as a **log-mel spectrogram**, because the conversion to decibels involves a
logarithmic operation. The above example used `librosa.power_to_db()` as `librosa.feature.melspectrogram()` creates a power spectrogram.

<Tip>
üí° Not all mel spectrograms are the same! There are two different mel scales in common use ("htk" and "slaney"),
and instead of the power spectrogram the amplitude spectrogram may be used. The conversion to a log-mel spectrogram doesn't
always compute true decibels but may simply take the `log`. Therefore, if a machine learning model expects a mel spectrogram
as input, double check to make sure you're computing it the same way.
</Tip>

Creating a mel spectrogram is a lossy operation as it involves filtering the signal. Converting a mel spectrogram back
into a waveform is more difficult than doing this for a regular spectrogram, as it requires estimating the frequencies
that were thrown away. This is why machine learning models such as HiFiGAN vocoder are needed to produce a waveform from a mel
spectrogram.

Compared to a standard spectrogram, a mel spectrogram can capture more meaningful features of the audio signal for
human perception, making it a popular choice in tasks such as speech recognition, speaker identification, and music genre classification.

Now that you know how to visualize audio data examples, go ahead and try to see what your favorite sounds look like. :)
