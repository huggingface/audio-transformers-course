# –î–æ–æ–±—É—á–µ–Ω–∏–µ SpeechT5

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –≤—ã –∑–Ω–∞–∫–æ–º—ã —Å –∑–∞–¥–∞—á–µ–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –º–æ–¥–µ–ª–∏ SpeechT5, –∫–æ—Ç–æ—Ä–∞—è –±—ã–ª–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–∞
–Ω–∞ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –¥–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –º—ã –º–æ–∂–µ–º –¥–æ–æ–±—É—á–∏—Ç—å –µ–µ –¥–ª—è –¥—Ä—É–≥–æ–≥–æ —è–∑—ã–∫–∞. 

## House-keeping

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä. –í –±–ª–æ–∫–Ω–æ—Ç–µ —ç—Ç–æ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å –ø–æ–º–æ—â—å—é —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã:

```bash
nvidia-smi
```

<Tip warning={true}>

–í –Ω–∞—à–µ–º –ø—Ä–∏–º–µ—Ä–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–∫–æ–ª–æ 40 —á–∞—Å–æ–≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —ç—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å, –∏—Å–ø–æ–ª—å–∑—É—è –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ–Ω—ã–π –ø–ª–∞–Ω Google Colab,
–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–º–µ–Ω—å—à–∏—Ç—å –æ–±—ä–µ–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–Ω–æ –¥–æ 10-15 —á–∞—Å–æ–≤ –∏ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è.

</Tip>

–í–∞–º —Ç–∞–∫–∂–µ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:  

```bash
pip install transformers datasets soundfile speechbrain accelerate
```

–ù–∞–∫–æ–Ω–µ—Ü, –Ω–µ –∑–∞–±—É–¥—å—Ç–µ –≤–æ–π—Ç–∏ –≤ —Å–≤–æ—é —É—á–µ—Ç–Ω—É—é –∑–∞–ø–∏—Å—å Hugging Face, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ—é –º–æ–¥–µ–ª—å –∏ –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –µ—é —Å —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º:

```py
from huggingface_hub import notebook_login

notebook_login()
```

## –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö

–í –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ –º—ã –≤–æ–∑—å–º–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–≥–æ (`nl`) —è–∑—ã–∫–∞ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ [VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli).
[VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) - —ç—Ç–æ –æ–±—à–∏—Ä–Ω—ã–π –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π —Ä–µ—á–µ–≤–æ–π –∫–æ—Ä–ø—É—Å, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –¥–∞–Ω–Ω—ã—Ö,
–ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∏–∑ –∑–∞–ø–∏—Å–µ–π –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –ï–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ –ø–∞—Ä–ª–∞–º–µ–Ω—Ç–∞ 2009-2020 –≥–≥. –û–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π –¥–ª—è 15 –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö —è–∑—ã–∫–æ–≤.
–•–æ—Ç—è –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–≥–æ —è–∑—ã–∫–∞, –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ.
 
–≠—Ç–æ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ (ASR), –ø–æ—ç—Ç–æ–º—É, –∫–∞–∫ —É–∂–µ –≥–æ–≤–æ—Ä–∏–ª–æ—Å—å, –æ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–º
–≤–∞—Ä–∏–∞–Ω—Ç–æ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è TTS-–º–æ–¥–µ–ª–µ–π. –û–¥–Ω–∞–∫–æ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ –±—É–¥–µ—Ç –≤–ø–æ–ª–Ω–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.

–î–∞–≤–∞–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ:

```python
from datasets import load_dataset, Audio

dataset = load_dataset("facebook/voxpopuli", "nl", split="train")
len(dataset)
```

**Output:**
```out
20968
```

20968 –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è. –î–ª—è SpeechT5 —Ç—Ä–µ–±—É–µ—Ç—Å—è, —á—Ç–æ–±—ã —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–ª—è–ª–∞ 16 –∫–ì—Ü, –ø–æ—ç—Ç–æ–º—É
—É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø—Ä–∏–º–µ—Ä—ã –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —ç—Ç–æ–º—É —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é:

```python
dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
```

## –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö 

–ù–∞—á–Ω–µ–º —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ç–æ—á–∫–∏ –º–æ–¥–µ–ª–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞, —Å–æ–¥–µ—Ä–∂–∞—â–µ–≥–æ –∫–∞–∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä,
—Ç–∞–∫ –∏ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –Ω–∞–º –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫ –æ–±—É—á–µ–Ω–∏—é: 

```py
from transformers import SpeechT5Processor

checkpoint = "microsoft/speecht5_tts"
processor = SpeechT5Processor.from_pretrained(checkpoint)
```

### –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ SpeechT5

–í–æ-–ø–µ—Ä–≤—ã—Ö, –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —á–∞—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ - —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, –ø–æ—ç—Ç–æ–º—É –≤–æ–∑—å–º–µ–º –µ–≥–æ:

```py
tokenizer = processor.tokenizer
```

–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä:

```python
dataset[0]
```

**Output:**
```out
{'audio_id': '20100210-0900-PLENARY-3-nl_20100210-09:06:43_4',
 'language': 9,
 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/02ec6a19d5b97c03e1379250378454dbf3fa2972943504a91c7da5045aa26a89/train_part_0/20100210-0900-PLENARY-3-nl_20100210-09:06:43_4.wav',
  'array': array([ 4.27246094e-04,  1.31225586e-03,  1.03759766e-03, ...,
         -9.15527344e-05,  7.62939453e-04, -2.44140625e-04]),
  'sampling_rate': 16000},
 'raw_text': 'Dat kan naar mijn gevoel alleen met een brede meerderheid die wij samen zoeken.',
 'normalized_text': 'dat kan naar mijn gevoel alleen met een brede meerderheid die wij samen zoeken.',
 'gender': 'female',
 'speaker_id': '1122',
 'is_gold_transcript': True,
 'accent': 'None'}
```

–ú–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ `raw_text` –∏ `normalized_text`. –ü—Ä–∏ –≤—ã–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–∞
–≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤–∞–∂–Ω–æ –∑–Ω–∞—Ç—å, —á—Ç–æ –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–µ SpeechT5 –Ω–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —á–∏—Å–µ–ª. –í `normalized_text`
—á–∏—Å–ª–∞ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ –≤–∏–¥–µ —Ç–µ–∫—Å—Ç–∞. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –æ–Ω –ª—É—á—à–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, –∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `normalized_text`.

–ü–æ—Å–∫–æ–ª—å–∫—É SpeechT5 –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ, –æ–Ω–∞ –º–æ–∂–µ—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏
–æ—Å—Ç–∞–≤–∏—Ç—å –≤—Å–µ –∫–∞–∫ –µ—Å—Ç—å, —Ç–æ —ç—Ç–∏ —Å–∏–º–≤–æ–ª—ã –±—É–¥—É—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –≤ —Ç–æ–∫–µ–Ω—ã `<unk>`. –û–¥–Ω–∞–∫–æ –≤ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–º —è–∑—ã–∫–µ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∏–º–≤–æ–ª—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä `√†`, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è
–¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–≥–æ–≤. –ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–º—ã—Å–ª —Ç–µ–∫—Å—Ç–∞, –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å —ç—Ç–æ—Ç —Å–∏–º–≤–æ–ª –Ω–∞ –æ–±—ã—á–Ω–æ–µ `a`.

–ß—Ç–æ–±—ã –≤—ã—è–≤–∏—Ç—å –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã, –∏–∑–≤–ª–µ—á–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é `SpeechT5Tokenizer`, –∫–æ—Ç–æ—Ä—ã–π
—Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Å–∏–º–≤–æ–ª–∞–º–∏ –∫–∞–∫ —Å —Ç–æ–∫–µ–Ω–∞–º–∏. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è `extract_all_chars`, –∫–æ—Ç–æ—Ä–∞—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç
—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏–∑ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –µ–µ –≤ –Ω–∞–±–æ—Ä —Å–∏–º–≤–æ–ª–æ–≤. [NL] 
–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞–π—Ç–µ `batched=True` –∏ `batch_size=-1` –≤ `dataset.map()`, —á—Ç–æ–±—ã –≤—Å–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –±—ã–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —Å—Ä–∞–∑—É –¥–ª—è
—Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.

```py
def extract_all_chars(batch):
    all_text = " ".join(batch["normalized_text"])
    vocab = list(set(all_text))
    return {"vocab": [vocab], "all_text": [all_text]}


vocabs = dataset.map(
    extract_all_chars,
    batched=True,
    batch_size=-1,
    keep_in_memory=True,
    remove_columns=dataset.column_names,
)

dataset_vocab = set(vocabs["vocab"][0])
tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}
```

–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –¥–≤–∞ –Ω–∞–±–æ—Ä–∞ —Å–∏–º–≤–æ–ª–æ–≤: –æ–¥–∏–Ω —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞, –¥—Ä—É–≥–æ–π - —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º –∏–∑ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞.
–î–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –≤–∑—è—Ç—å —Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É —ç—Ç–∏–º–∏ –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏. –ü–æ–ª—É—á–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä
–±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–µ.

```py
dataset_vocab - tokenizer_vocab
```

**Output:**
```out
{' ', '√†', '√ß', '√®', '√´', '√≠', '√Ø', '√∂', '√º'}
```

–î–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏, –≤—ã—è–≤–ª–µ–Ω–Ω—ã–º–∏ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —ç—Ç–∞–ø–µ, –º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç —ç—Ç–∏ —Å–∏–º–≤–æ–ª—ã —Å –¥–æ–ø—É—Å—Ç–∏–º—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏.
–ó–∞–º–µ—Ç–∏–º, —á—Ç–æ –ø—Ä–æ–±–µ–ª—ã —É–∂–µ –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ `‚ñÅ` –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–µ –∏ –Ω–µ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ.

```py
replacements = [
    ("√†", "a"),
    ("√ß", "c"),
    ("√®", "e"),
    ("√´", "e"),
    ("√≠", "i"),
    ("√Ø", "i"),
    ("√∂", "o"),
    ("√º", "u"),
]


def cleanup_text(inputs):
    for src, dst in replacements:
        inputs["normalized_text"] = inputs["normalized_text"].replace(src, dst)
    return inputs


dataset = dataset.map(cleanup_text)
```

–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –º—ã —Ä–∞–∑–æ–±—Ä–∞–ª–∏—Å—å —Å–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ –≤ —Ç–µ–∫—Å—Ç–µ, –ø—Ä–∏—à–ª–æ –≤—Ä–µ–º—è –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ.

### –î–∏–∫—Ç–æ—Ä—ã

–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö VoxPopuli –≤–∫–ª—é—á–∞–µ—Ç —Ä–µ—á—å –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–∏–∫—Ç–æ—Ä–æ–≤, –Ω–æ —Å–∫–æ–ª—å–∫–æ –¥–∏–∫—Ç–æ—Ä–æ–≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ –≤ –Ω–∞–±–æ—Ä–µ? –ß—Ç–æ–±—ã
–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —ç—Ç–æ, –º—ã –º–æ–∂–µ–º –ø–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∏–∫—Ç–æ—Ä–æ–≤ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∫–∞–∂–¥—ã–π –¥–∏–∫—Ç–æ—Ä –≤–Ω–æ—Å–∏—Ç –≤ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö.
–£—á–∏—Ç—ã–≤–∞—è, —á—Ç–æ –≤—Å–µ–≥–æ –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö 20 968 –ø—Ä–∏–º–µ—Ä–æ–≤, —ç—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª–∏—Ç –Ω–∞–º –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
–¥–∏–∫—Ç–æ—Ä–æ–≤ –∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö.

```py
from collections import defaultdict

speaker_counts = defaultdict(int)

for speaker_id in dataset["speaker_id"]:
    speaker_counts[speaker_id] += 1
```

–ü–æ—Å—Ç—Ä–æ–∏–≤ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É, –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ç–æ–º, —Å–∫–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã—Ö –∏–º–µ–µ—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∏–∫—Ç–æ—Ä–∞.

```py
import matplotlib.pyplot as plt

plt.figure()
plt.hist(speaker_counts.values(), bins=20)
plt.ylabel("Speakers")
plt.xlabel("Examples")
plt.show()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_speakers_histogram.png" alt="Speakers histogram"/>
</div>

–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç—Ä–µ—Ç—å –¥–∏–∫—Ç–æ—Ä–æ–≤ –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –∏–º–µ–µ—Ç –º–µ–Ω–µ–µ 100 –ø—Ä–∏–º–µ—Ä–æ–≤, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫
–æ–∫–æ–ª–æ –¥–µ—Å—è—Ç–∏ –¥–∏–∫—Ç–æ—Ä–æ–≤ –∏–º–µ—é—Ç –±–æ–ª–µ–µ 500 –ø—Ä–∏–º–µ—Ä–æ–≤. –ß—Ç–æ–±—ã –ø–æ–≤—ã—Å–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, –º—ã –º–æ–∂–µ–º –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å
–¥–∞–Ω–Ω—ã–µ –¥–∏–∫—Ç–æ—Ä–∞–º–∏, –∏–º–µ—é—â–∏–º–∏ –æ—Ç 100 –¥–æ 400 –ø—Ä–∏–º–µ—Ä–æ–≤.

```py
def select_speaker(speaker_id):
    return 100 <= speaker_counts[speaker_id] <= 400


dataset = dataset.filter(select_speaker, input_columns=["speaker_id"])
```

–ü—Ä–æ–≤–µ—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∏–∫—Ç–æ—Ä–æ–≤:

```py
len(set(dataset["speaker_id"]))
```

**Output:**
```out
42
```

–ü–æ—Å–º–æ—Ç—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ –æ—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏–º–µ—Ä–æ–≤:

```py
len(dataset)
```

**Output:**
```out
9973
```

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ —á—É—Ç—å –º–µ–Ω–µ–µ 10 000 –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –ø—Ä–∏–º–µ—Ä–Ω–æ 40 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∏–∫—Ç–æ—Ä–æ–≤, —á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤–ø–æ–ª–Ω–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.

–û—Ç–º–µ—Ç–∏–º, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∏–∫—Ç–æ—Ä—ã —Å –Ω–µ–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤ –º–æ–≥—É—Ç –∏–º–µ—Ç—å –±–æ–ª—å—à–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤, –µ—Å–ª–∏ –ø—Ä–∏–º–µ—Ä—ã –¥–ª–∏–Ω–Ω—ã–µ. –û–¥–Ω–∞–∫–æ
–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –æ–±—ä–µ–º–∞ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∏–∫—Ç–æ—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è
—Ç—Ä—É–¥–æ–µ–º–∫–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º, –≤–∫–ª—é—á–∞—é—â–∏–º –∑–∞–≥—Ä—É–∑–∫—É –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞. –ü–æ—ç—Ç–æ–º—É –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –º—ã —Ä–µ—à–∏–ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ—Ç —ç—Ç–∞–ø.

### –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞

–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å TTS –º–æ–≥–ª–∞ —Ä–∞–∑–ª–∏—á–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–∏–∫—Ç–æ—Ä–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞.
–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–æ–≤ - —ç—Ç–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤—Ö–æ–¥ –¥–ª—è –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–π —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≥–æ–ª–æ—Å–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–∏–∫—Ç–æ—Ä–∞.
–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–∏–∫—Ç–æ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å [spkrec-xvect-voxceleb](https://huggingface.co/speechbrain/spkrec-xvect-voxceleb)
–æ—Ç SpeechBrain. 

–°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é `create_speaker_embedding()`, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≤—Ö–æ–¥–Ω—É—é –≤–æ–ª–Ω–æ–≤—É—é —Ñ–æ—Ä–º—É –∑–≤—É–∫–∞ –∏ –≤—ã–¥–∞–µ—Ç 512-—ç–ª–µ–º–µ–Ω—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä,
—Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞.

```py
import os
import torch
from speechbrain.pretrained import EncoderClassifier

spk_model_name = "speechbrain/spkrec-xvect-voxceleb"

device = "cuda" if torch.cuda.is_available() else "cpu"
speaker_model = EncoderClassifier.from_hparams(
    source=spk_model_name,
    run_opts={"device": device},
    savedir=os.path.join("/tmp", spk_model_name),
)


def create_speaker_embedding(waveform):
    with torch.no_grad():
        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))
        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)
        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()
    return speaker_embeddings
```

–í–∞–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ –º–æ–¥–µ–ª—å `speechbrain/spkrec-xvect-voxceleb` –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–π —Ä–µ—á–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ VoxCeleb,
–≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ —É—á–µ–±–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤ –¥–∞–Ω–Ω–æ–º —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –Ω–∞ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–º —è–∑—ã–∫–µ. –•–æ—Ç—è –º—ã —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≤—Å–µ —Ä–∞–≤–Ω–æ –±—É–¥–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑—É–º–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞
–¥–ª—è –Ω–∞—à–µ–≥–æ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞, —ç—Ç–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ –Ω–µ –≤–æ –≤—Å–µ—Ö —Å–ª—É—á–∞—è—Ö.

–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å X-–≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞ —Ü–µ–ª–µ–≤–æ–π —Ä–µ—á–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –º–æ–¥–µ–ª–∏
–ª—É—á—à–µ —É–ª–∞–≤–ª–∏–≤–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–µ—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –ø—Ä–∏—Å—É—â–∏–µ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–º—É —è–∑—ã–∫—É. –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –æ–±—É—á–∏—Ç—å —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é X-–≤–µ–∫—Ç–æ—Ä–Ω—É—é –º–æ–¥–µ–ª—å,
—Ç–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–º–µ—Ä–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [—ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç](https://huggingface.co/mechanicalsea/speecht5-vc/blob/main/manifest/utils/prep_cmu_arctic_spkemb.py).   

### –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

–ù–∞–∫–æ–Ω–µ—Ü, –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç –º–æ–¥–µ–ª—å. –°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é `prepare_dataset`, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç
–æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç `SpeechT5Processor` –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Ü–µ–ª–µ–≤–æ–≥–æ –∞—É–¥–∏–æ –≤ –ª–æ–≥-–º–µ–ª —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É.
–û–Ω–∞ —Ç–∞–∫–∂–µ –¥–æ–ª–∂–Ω–∞ –¥–æ–±–∞–≤–ª—è—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞.

```py
def prepare_dataset(example):
    audio = example["audio"]

    example = processor(
        text=example["normalized_text"],
        audio_target=audio["array"],
        sampling_rate=audio["sampling_rate"],
        return_attention_mask=False,
    )

    # strip off the batch dimension
    example["labels"] = example["labels"][0]

    # use SpeechBrain to obtain x-vector
    example["speaker_embeddings"] = create_speaker_embedding(audio["array"])

    return example
```

–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–∂–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤:

```py
processed_example = prepare_dataset(dataset[0])
list(processed_example.keys())
```

**Output:**
```out
['input_ids', 'labels', 'stop_labels', 'speaker_embeddings']
```

–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞ –¥–æ–ª–∂–Ω—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Å–æ–±–æ–π 512-—ç–ª–µ–º–µ–Ω—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä:

```py
processed_example["speaker_embeddings"].shape
```

**Output:**
```out
(512,)
```

–ú–µ—Ç–∫–∏ –¥–æ–ª–∂–Ω—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Å–æ–±–æ–π –ª–æ–≥-–º–µ–ª —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É —Å 80 –º–µ–ª –±–∏–Ω–∞–º–∏.

```py
import matplotlib.pyplot as plt

plt.figure()
plt.imshow(processed_example["labels"].T)
plt.show()
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/tts_logmelspectrogram_1.png" alt="Log-mel spectrogram with 80 mel bins"/>
</div>

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ï—Å–ª–∏ –¥–∞–Ω–Ω–∞—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞ –∫–∞–∂–µ—Ç—Å—è –≤–∞–º –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ–π, —Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ –≤—ã –ø—Ä–∏–≤—ã–∫–ª–∏ —Ä–∞—Å–ø–æ–ª–∞–≥–∞—Ç—å –Ω–∏–∑–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã
–≤–Ω–∏–∑—É, –∞ –≤—ã—Å–æ–∫–∏–µ - –≤–≤–µ—Ä—Ö—É –≥—Ä–∞—Ñ–∏–∫–∞. –û–¥–Ω–∞–∫–æ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –≤ –≤–∏–¥–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ matplotlib –æ—Å—å y
–ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç—Å—è, –∏ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –≤—ã–≥–ª—è–¥—è—Ç –ø–µ—Ä–µ–≤–µ—Ä–Ω—É—Ç—ã–º–∏.

–¢–µ–ø–µ—Ä—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –∫–æ –≤—Å–µ–º—É –Ω–∞–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö. –≠—Ç–æ –∑–∞–π–º–µ—Ç –æ—Ç 5 –¥–æ 10 –º–∏–Ω—É—Ç.

```py
dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)
```

–ü–æ—è–≤–∏—Ç—Å—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Ç–æ–º, —á—Ç–æ –¥–ª–∏–Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å (600 –ª–µ–∫—Å–µ–º).
–£–¥–∞–ª–∏—Ç–µ —ç—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞. –ó–¥–µ—Å—å –º—ã –∏–¥–µ–º –µ—â–µ –¥–∞–ª—å—à–µ –∏ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, —É–¥–∞–ª—è–µ–º –≤—Å–µ, —á—Ç–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 200 —Ç–æ–∫–µ–Ω–æ–≤.

```py
def is_not_too_long(input_ids):
    input_length = len(input_ids)
    return input_length < 200


dataset = dataset.filter(is_not_too_long, input_columns=["input_ids"])
len(dataset)
```

**Output:**
```out
8259
```

–ó–∞—Ç–µ–º —Å–æ–∑–¥–∞–¥–∏–º –±–∞–∑–æ–≤–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é —á–∞—Å—Ç–∏:

```py
dataset = dataset.train_test_split(test_size=0.1)
```

### –ö–æ–ª–ª–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö

–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –±–∞—Ç—á, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–ª–ª–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö. –≠—Ç–æ—Ç –∫–æ–ª–ª–∞—Ç–æ—Ä –±—É–¥–µ—Ç –¥–æ–ø–æ–ª–Ω—è—Ç—å –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞–º–∏,
–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—è, —á—Ç–æ –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã –±—É–¥—É—Ç –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É. –î–ª—è –º–µ—Ç–æ–∫ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –¥–æ–ø–æ–ª–Ω—è–µ–º–∞—è —á–∞—Å—Ç–∏ –∑–∞–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ `-100`.
–≠—Ç–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —É–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ç—É —á–∞—Å—Ç—å —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø–æ—Ç–µ—Ä—å —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã.

```py
from dataclasses import dataclass
from typing import Any, Dict, List, Union


@dataclass
class TTSDataCollatorWithPadding:
    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        input_ids = [{"input_ids": feature["input_ids"]} for feature in features]
        label_features = [{"input_values": feature["labels"]} for feature in features]
        speaker_features = [feature["speaker_embeddings"] for feature in features]

        # collate the inputs and targets into a batch
        batch = processor.pad(
            input_ids=input_ids, labels=label_features, return_tensors="pt"
        )

        # replace padding with -100 to ignore loss correctly
        batch["labels"] = batch["labels"].masked_fill(
            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100
        )

        # not used during fine-tuning
        del batch["decoder_attention_mask"]

        # round down target lengths to multiple of reduction factor
        if model.config.reduction_factor > 1:
            target_lengths = torch.tensor(
                [len(feature["input_values"]) for feature in label_features]
            )
            target_lengths = target_lengths.new(
                [
                    length - length % model.config.reduction_factor
                    for length in target_lengths
                ]
            )
            max_length = max(target_lengths)
            batch["labels"] = batch["labels"][:, :max_length]

        # also add in the speaker embeddings
        batch["speaker_embeddings"] = torch.tensor(speaker_features)

        return batch
```

–í SpeechT5 –≤—Ö–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –¥–µ–∫–æ–¥–µ—Ä–∞ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤ 2 —Ä–∞–∑–∞. –î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π –≤—Ç–æ—Ä–æ–π 
–≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥ –∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.–ó–∞—Ç–µ–º –¥–µ–∫–æ–¥–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –≤ –¥–≤–∞ —Ä–∞–∑–∞ –¥–ª–∏–Ω–Ω–µ–µ. –ü–æ—Å–∫–æ–ª—å–∫—É –∏—Å—Ö–æ–¥–Ω–∞—è –¥–ª–∏–Ω–∞
—Ü–µ–ª–µ–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ [NL] –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—á–µ—Ç–Ω–æ–π, –∫–æ–ª–ª–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ–∫—Ä—É–≥–ª—è–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –±–∞—Ç—á–∞ –¥–æ –∑–Ω–∞—á–µ–Ω–∏—è [NL], –∫—Ä–∞—Ç–Ω–æ–≥–æ 2.

```py 
data_collator = TTSDataCollatorWithPadding(processor=processor)
```

## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

–ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ —Ç–æ–π –∂–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ç–æ—á–∫–∏, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞: 

```py
from transformers import SpeechT5ForTextToSpeech

model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)
```

–û–ø—Ü–∏—è `use_cache=True` –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫. –û—Ç–∫–ª—é—á–∏—Ç–µ –µ–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Å–Ω–æ–≤–∞ –≤–∫–ª—é—á–∏—Ç–µ –∫—ç—à –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏,
—á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å  –∏–Ω—Ñ–µ—Ä–µ–Ω—Å:

```py 
from functools import partial

# –æ—Ç–∫–ª—é—á–∏—Ç—å –∫—ç—à –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º–∏ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–º–∏ —Ç–æ—á–∫–∞–º–∏
model.config.use_cache = False

# –∑–∞–¥–∞–Ω–∏–º —è–∑—ã–∫ –∏ –∑–∞–¥–∞—á—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Å–Ω–æ–≤–∞ –≤–∫–ª—é—á–∏–º –∫—ç—à
model.generate = partial(model.generate, use_cache=True)
``` 

–û–ø—Ä–µ–¥–µ–ª–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è. –ó–¥–µ—Å—å –º—ã –Ω–µ –≤—ã—á–∏—Å–ª—è–µ–º –Ω–∏–∫–∞–∫–∏—Ö –æ—Ü–µ–Ω–æ—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è,
–º—ã –ø–æ–≥–æ–≤–æ—Ä–∏–º –æ–± –æ—Ü–µ–Ω–∫–µ –ø–æ–∑–∂–µ –≤ —ç—Ç–æ–π –≥–ª–∞–≤–µ. –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –º—ã –±—É–¥–µ–º —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Ç–µ—Ä–∏:

```python
from transformers import Seq2SeqTrainingArguments

training_args = Seq2SeqTrainingArguments(
    output_dir="speecht5_finetuned_voxpopuli_nl",  # change to a repo name of your choice
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,
    learning_rate=1e-5,
    warmup_steps=500,
    max_steps=4000,
    gradient_checkpointing=True,
    fp16=True,
    evaluation_strategy="steps",
    per_device_eval_batch_size=2,
    save_steps=1000,
    eval_steps=1000,
    logging_steps=25,
    report_to=["tensorboard"],
    load_best_model_at_end=True,
    greater_is_better=False,
    label_names=["labels"],
    push_to_hub=True,
)
```

–ò–Ω—Å—Ç–∞–Ω—Ü–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç `Trainer` –∏ –ø–µ—Ä–µ–¥–∞–µ–º –µ–º—É –º–æ–¥–µ–ª—å, –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ –∫–æ–ª–ª–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö.

```py
from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    args=training_args,
    model=model,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    data_collator=data_collator,
    tokenizer=processor,
)
```

–ò —Å —ç—Ç–∏–º –º—ã –≥–æ—Ç–æ–≤—ã –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ –æ–±—É—á–µ–Ω–∏—é! –û–±—É—á–µ–Ω–∏–µ –∑–∞–π–º–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ GPU
–≤–æ–∑–º–æ–∂–Ω–æ, —á—Ç–æ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –æ—à–∏–±–∫–∞ CUDA "out-of-memory". –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å
—Ä–∞–∑–º–µ—Ä `per_device_train_batch_size` –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –≤ 2 —Ä–∞–∑–∞ –∏ —É–≤–µ–ª–∏—á–∏—Ç—å `gradient_accumulation_steps` –≤ 2 —Ä–∞–∑–∞, —á—Ç–æ–±—ã –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ.

```py
trainer.train()
```

Push the final model to the ü§ó Hub:

```py
trainer.push_to_hub()
```

## –ò–Ω—Ñ–µ—Ä–µ–Ω—Å

–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –º–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞, –µ–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞! –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–∑ ü§ó Hub (—É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤
—Å–ª–µ–¥—É—é—â–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ –∫–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–º—è –≤–∞—à–µ–π —É—á–µ—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏):

```py
model = SpeechT5ForTextToSpeech.from_pretrained(
    "YOUR_ACCOUNT/speecht5_finetuned_voxpopuli_nl"
)
```

–í—ã–±–µ—Ä–µ–º –ø—Ä–∏–º–µ—Ä, –∑–¥–µ—Å—å –º—ã –≤–æ–∑—å–º–µ–º –ø—Ä–∏–º–µ—Ä –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞.

```py 
example = dataset["test"][304]
speaker_embeddings = torch.tensor(example["speaker_embeddings"]).unsqueeze(0)
```

–û–ø—Ä–µ–¥–µ–ª–∏–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –µ–≥–æ.

```py 
text = "hallo allemaal, ik praat nederlands. groetjes aan iedereen!"
```

–í—ã–ø–æ–ª–Ω–∏–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:

```py
inputs = processor(text=text, return_tensors="pt")
```

–ò–Ω—Å—Ç–∞–Ω—Ü–∏—Ä—É–µ–º –≤–æ–∫–æ–¥–µ—Ä –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—á—å: 

```py
from transformers import SpeechT5HifiGan

vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
speech = model.generate_speech(inputs["input_ids"], speaker_embeddings, vocoder=vocoder)
```

–ì–æ—Ç–æ–≤—ã –ø–æ—Å–ª—É—à–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç?

```py
from IPython.display import Audio

Audio(speech.numpy(), rate=16000)
```

–ü–æ–ª—É—á–µ–Ω–∏–µ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤–æ–º —è–∑—ã–∫–µ –º–æ–∂–µ—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è –Ω–µ–ø—Ä–æ—Å—Ç–æ–π –∑–∞–¥–∞—á–µ–π. –ö–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–∏–∫—Ç–æ—Ä–∞
–º–æ–∂–µ—Ç –±—ã—Ç—å —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ñ–∞–∫—Ç–æ—Ä–æ–º. –ü–æ—Å–∫–æ–ª—å–∫—É SpeechT5 –±—ã–ª–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö x-–≤–µ–∫—Ç–æ—Ä–∞—Ö, –æ–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
–ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –¥–∏–∫—Ç–æ—Ä–æ–≤. –ï—Å–ª–∏ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–µ—á—å –∑–≤—É—á–∏—Ç –ø–ª–æ—Ö–æ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–∫—Ç–æ—Ä–∞.

–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Ç–∞–∫–∂–µ –ø–æ–≤—ã—Å–∏—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —ç—Ç–æ, —Ä–µ—á—å —è–≤–Ω–æ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–∞—è, –∞ –Ω–µ –∞–Ω–≥–ª–∏–π—Å–∫–∞—è, –∏ –≤ –Ω–µ–π
–ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≥–æ–ª–æ—Å–∞ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ (—Å—Ä–∞–≤–Ω–∏—Ç–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞—É–¥–∏–æ –≤ –ø—Ä–∏–º–µ—Ä–µ).
–ï—â–µ –æ–¥–∏–Ω –º–æ–º–µ–Ω—Ç, —Å –∫–æ—Ç–æ—Ä—ã–º –º–æ–∂–Ω–æ –ø–æ—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, - —ç—Ç–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `config.reduction_factor = 1`, —á—Ç–æ–±—ã
–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, —É–ª—É—á—à–∏—Ç –ª–∏ —ç—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

–í —Å–ª–µ–¥—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã —Ä–∞—Å—Å–∫–∞–∂–µ–º –æ —Ç–æ–º, –∫–∞–∫ –º—ã –æ—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å. 
